{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNRvSnJezdP9NYZTfWQ2zQV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# üî• Train ResNet-50 on Real Data Only (D-Fire)\n","\n","This notebook implements the baseline fire classification model using only real-world images from the D-Fire dataset. We fine-tune a pretrained ResNet-50 model to distinguish between \"fire\" and \"no fire\" images in a binary classification task.\n","\n","This baseline will later be compared to models trained on different combinations of synthetic and real data. The model's performance will be evaluated using accuracy, precision, recall, and F1-score on a held-out test set of real images.\n","\n","üìå **Objectives:**\n","- Load and split the real D-Fire dataset\n","- Train ResNet-50 for binary fire classification\n","- Log training metrics and save the best-performing model\n","- Prepare for comparison with future synthetic+real experiments\n"],"metadata":{"id":"WrwUMilG1gEx"}},{"cell_type":"markdown","source":["## üì¶ Notebook Setup: Mount Drive & Clone GitHub Repo\n","\n","This cell ensures the notebook is reproducible in any new Colab session by:\n","\n","- Mounting your Google Drive (to access datasets, secrets, and checkpoints)\n","- Loading your GitHub token from Drive\n","- Cloning the fire-detection-dissertation repository\n","- Navigating into the correct folder\n","- Setting Git identity for future commits\n","\n","‚ö†Ô∏è **Note:** This cell must be run every time you open this notebook in a new Colab session.\n"],"metadata":{"id":"7t63wO6t1kat"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rsuwo_vTwg-y","executionInfo":{"status":"ok","timestamp":1751640783052,"user_tz":-60,"elapsed":20106,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"6a660ae3-78fe-4779-dbe5-a4622c92b97d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content\n","Cloning into 'fire-detection-dissertation'...\n","remote: Enumerating objects: 30, done.\u001b[K\n","remote: Counting objects: 100% (30/30), done.\u001b[K\n","remote: Compressing objects: 100% (22/22), done.\u001b[K\n","remote: Total 30 (delta 9), reused 23 (delta 6), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (30/30), 176.77 KiB | 16.07 MiB/s, done.\n","Resolving deltas: 100% (9/9), done.\n","/content/fire-detection-dissertation\n"]}],"source":["# üîß Minimal Colab setup for any working notebook\n","\n","# 1. Mount Google Drive\n","import os\n","from google.colab import drive\n","if not os.path.ismount(\"/content/drive\"):\n","    drive.mount(\"/content/drive\")\n","\n","# 2. Load GitHub token securely from Drive\n","token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n","with open(token_path, \"r\") as f:\n","    token = f.read().strip()\n","\n","# 3. Clone the GitHub repo (force fresh clone for safety)\n","username = \"Misharasapu\"\n","repo = \"fire-detection-dissertation\"\n","clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n","repo_path = f\"/content/{repo}\"\n","\n","# Optional: Remove old clone (safe to rerun)\n","!rm -rf {repo_path}\n","\n","# Clone fresh and move into the repo\n","%cd /content\n","!git clone {clone_url}\n","%cd {repo}\n","\n","# 4. Set Git identity (required in Colab sessions)\n","!git config --global user.name \"Misharasapu\"\n","!git config --global user.email \"misharasapu@gmail.com\"\n"]},{"cell_type":"markdown","source":["## üîπ Step 1: Load & Split the Real Dataset (Train/Val Only)\n","\n","In this step, we load the real-world D-Fire dataset using the `FireClassificationDataset` class and divide it into training and validation subsets. The separate test set remains untouched, as it will be reserved for final model evaluation after all experiments are complete.\n","\n","Each image in the dataset is paired with a YOLO-style `.txt` label file:\n","- `class_id == 1` indicates fire (labelled as `1`)\n","- `class_id == 0` indicates smoke only (labelled as `0`)\n","- Missing or empty `.txt` files also result in label `0`\n","\n","These labels are processed automatically inside the dataset class. After loading, we use an 80/20 split to create training and validation sets, followed by wrapping each in a `DataLoader` for efficient batching during training.\n","\n","This step ensures the model learns from real-world examples while maintaining a consistent and reproducible split strategy.\n"],"metadata":{"id":"vP3StHLb2Oq-"}},{"cell_type":"code","source":["import torch\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import transforms\n","from utils.fire_classification_dataset import FireClassificationDataset\n","\n","# Define image transforms: resize to 224x224 and convert to tensor\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","# Set paths to D-Fire training images and YOLO label files\n","image_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/images\"\n","label_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/labels\"\n","\n","# Load full dataset using the custom Dataset class\n","full_dataset = FireClassificationDataset(image_dir=image_dir, label_dir=label_dir, transform=transform)\n","\n","# Split dataset into training and validation subsets (80/20 split)\n","train_ratio = 0.8\n","train_size = int(train_ratio * len(full_dataset))\n","val_size = len(full_dataset) - train_size\n","\n","# Use a fixed seed to ensure reproducible splits\n","generator = torch.Generator().manual_seed(42)\n","train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n","\n","# Wrap subsets in DataLoaders for batching and shuffling\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","\n","# üîç Confirm dataset sizes\n","print(f\"Total samples in full dataset: {len(full_dataset)}\")\n","print(f\"Training samples: {len(train_dataset)}\")\n","print(f\"Validation samples: {len(val_dataset)}\")\n","\n","# üîç Preview one batch from the train_loader\n","train_batch = next(iter(train_loader))\n","images, labels = train_batch\n","\n","print(f\"\\nBatch shape (images): {images.shape}\")   # Expected: (32, 3, 224, 224)\n","print(f\"Batch shape (labels): {labels.shape}\")     # Expected: (32,)\n","print(f\"Sample labels: {labels.tolist()}\")         # Quick look at a label distribution\n","\n"],"metadata":{"id":"xt7XDeWz1pTZ","executionInfo":{"status":"ok","timestamp":1751393732144,"user_tz":-60,"elapsed":188990,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"2af67731-e4bb-4c1f-bc2b-8d60720f5ad9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total samples in full dataset: 17222\n","Training samples: 13777\n","Validation samples: 3445\n","\n","Batch shape (images): torch.Size([32, 3, 224, 224])\n","Batch shape (labels): torch.Size([32])\n","Sample labels: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"]}]},{"cell_type":"markdown","source":["## üîπ Step 2: Load and Modify ResNet-50 for Binary Classification\n","\n","In this step, we load a pretrained ResNet-50 model from PyTorch's `torchvision.models` library and modify its output layer to suit our binary classification task (fire vs. no fire).\n","\n","By default, ResNet-50 is trained on ImageNet with 1000 output classes. We will:\n","- Load the pretrained model with its existing weights\n","- Freeze the convolutional layers to retain pretrained features (optional, can be unfrozen later)\n","- Replace the final fully connected (FC) layer with a new linear layer for 2-class output\n","\n","This fine-tuning approach allows us to benefit from transfer learning ‚Äî leveraging the rich feature representations learned from large-scale natural image data, while adapting the final classification head to our specific fire detection task.\n"],"metadata":{"id":"KYBVaFoyIV3y"}},{"cell_type":"code","source":["import torch.nn as nn\n","from torchvision import models\n","\n","# Load pretrained ResNet-50 model from torchvision\n","resnet = models.resnet50(pretrained=True)\n","\n","# Optional: Freeze all layers except the final classification head\n","# This prevents updating the weights in the backbone during training\n","for param in resnet.parameters():\n","    param.requires_grad = False\n","\n","# Get the number of input features to the original final layer\n","in_features = resnet.fc.in_features  # Expected: 2048\n","\n","# Replace the original 1000-class FC layer with a new 2-class layer\n","resnet.fc = nn.Linear(in_features, 2)\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","resnet = resnet.to(device)\n","\n","# Print model summary (optional)\n","print(resnet)\n","\n","# Optional: Print detailed model summary using torchinfo\n","!pip install torchinfo\n","from torchinfo import summary\n","\n","# Show summary for input batch size of 32 (3 channels, 224x224 resolution)\n","summary(resnet, input_size=(32, 3, 224, 224))\n","\n"],"metadata":{"id":"BxZzZI3N5uX_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751394061500,"user_tz":-60,"elapsed":8087,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"b86cdeeb-df9a-4d0e-ae15-9f09e9c44f18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (3): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (4): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (5): Bottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): Bottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","    (2): Bottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",")\n","Collecting torchinfo\n","  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n","Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n","Installing collected packages: torchinfo\n","Successfully installed torchinfo-1.8.0\n"]},{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                   Output Shape              Param #\n","==========================================================================================\n","ResNet                                   [32, 2]                   --\n","‚îú‚îÄConv2d: 1-1                            [32, 64, 112, 112]        (9,408)\n","‚îú‚îÄBatchNorm2d: 1-2                       [32, 64, 112, 112]        (128)\n","‚îú‚îÄReLU: 1-3                              [32, 64, 112, 112]        --\n","‚îú‚îÄMaxPool2d: 1-4                         [32, 64, 56, 56]          --\n","‚îú‚îÄSequential: 1-5                        [32, 256, 56, 56]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-1                   [32, 256, 56, 56]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                  [32, 64, 56, 56]          (4,096)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-2             [32, 64, 56, 56]          (128)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-3                    [32, 64, 56, 56]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-4                  [32, 64, 56, 56]          (36,864)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-5             [32, 64, 56, 56]          (128)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-6                    [32, 64, 56, 56]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-7                  [32, 256, 56, 56]         (16,384)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-8             [32, 256, 56, 56]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-9              [32, 256, 56, 56]         (16,896)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-10                   [32, 256, 56, 56]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-2                   [32, 256, 56, 56]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-11                 [32, 64, 56, 56]          (16,384)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-12            [32, 64, 56, 56]          (128)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-13                   [32, 64, 56, 56]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                 [32, 64, 56, 56]          (36,864)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-15            [32, 64, 56, 56]          (128)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-16                   [32, 64, 56, 56]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                 [32, 256, 56, 56]         (16,384)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-18            [32, 256, 56, 56]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-19                   [32, 256, 56, 56]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-3                   [32, 256, 56, 56]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-20                 [32, 64, 56, 56]          (16,384)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-21            [32, 64, 56, 56]          (128)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-22                   [32, 64, 56, 56]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-23                 [32, 64, 56, 56]          (36,864)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-24            [32, 64, 56, 56]          (128)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-25                   [32, 64, 56, 56]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-26                 [32, 256, 56, 56]         (16,384)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-27            [32, 256, 56, 56]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-28                   [32, 256, 56, 56]         --\n","‚îú‚îÄSequential: 1-6                        [32, 512, 28, 28]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-4                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-29                 [32, 128, 56, 56]         (32,768)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-30            [32, 128, 56, 56]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-31                   [32, 128, 56, 56]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-32                 [32, 128, 28, 28]         (147,456)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-33            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-34                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-35                 [32, 512, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-36            [32, 512, 28, 28]         (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-37             [32, 512, 28, 28]         (132,096)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-38                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-5                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-39                 [32, 128, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-40            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-41                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-42                 [32, 128, 28, 28]         (147,456)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-43            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-44                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-45                 [32, 512, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-46            [32, 512, 28, 28]         (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-47                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-6                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-48                 [32, 128, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-49            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-50                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-51                 [32, 128, 28, 28]         (147,456)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-52            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-53                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-54                 [32, 512, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-55            [32, 512, 28, 28]         (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-56                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-7                   [32, 512, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-57                 [32, 128, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-58            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-59                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-60                 [32, 128, 28, 28]         (147,456)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-61            [32, 128, 28, 28]         (256)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-62                   [32, 128, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-63                 [32, 512, 28, 28]         (65,536)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-64            [32, 512, 28, 28]         (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-65                   [32, 512, 28, 28]         --\n","‚îú‚îÄSequential: 1-7                        [32, 1024, 14, 14]        --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-8                   [32, 1024, 14, 14]        --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-66                 [32, 256, 28, 28]         (131,072)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-67            [32, 256, 28, 28]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-68                   [32, 256, 28, 28]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-69                 [32, 256, 14, 14]         (589,824)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-70            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-71                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-72                 [32, 1024, 14, 14]        (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-73            [32, 1024, 14, 14]        (2,048)\n","‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-74             [32, 1024, 14, 14]        (526,336)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-75                   [32, 1024, 14, 14]        --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-9                   [32, 1024, 14, 14]        --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-76                 [32, 256, 14, 14]         (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-77            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-78                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-79                 [32, 256, 14, 14]         (589,824)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-80            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-81                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-82                 [32, 1024, 14, 14]        (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-83            [32, 1024, 14, 14]        (2,048)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-84                   [32, 1024, 14, 14]        --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-10                  [32, 1024, 14, 14]        --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-85                 [32, 256, 14, 14]         (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-86            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-87                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-88                 [32, 256, 14, 14]         (589,824)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-89            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-90                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-91                 [32, 1024, 14, 14]        (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-92            [32, 1024, 14, 14]        (2,048)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-93                   [32, 1024, 14, 14]        --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-11                  [32, 1024, 14, 14]        --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-94                 [32, 256, 14, 14]         (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-95            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-96                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-97                 [32, 256, 14, 14]         (589,824)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-98            [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-99                   [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-100                [32, 1024, 14, 14]        (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-101           [32, 1024, 14, 14]        (2,048)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-102                  [32, 1024, 14, 14]        --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-12                  [32, 1024, 14, 14]        --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-103                [32, 256, 14, 14]         (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-104           [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-105                  [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-106                [32, 256, 14, 14]         (589,824)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-107           [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-108                  [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-109                [32, 1024, 14, 14]        (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-110           [32, 1024, 14, 14]        (2,048)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-111                  [32, 1024, 14, 14]        --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-13                  [32, 1024, 14, 14]        --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-112                [32, 256, 14, 14]         (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-113           [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-114                  [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-115                [32, 256, 14, 14]         (589,824)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-116           [32, 256, 14, 14]         (512)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-117                  [32, 256, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-118                [32, 1024, 14, 14]        (262,144)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-119           [32, 1024, 14, 14]        (2,048)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-120                  [32, 1024, 14, 14]        --\n","‚îú‚îÄSequential: 1-8                        [32, 2048, 7, 7]          --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-14                  [32, 2048, 7, 7]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-121                [32, 512, 14, 14]         (524,288)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-122           [32, 512, 14, 14]         (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-123                  [32, 512, 14, 14]         --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-124                [32, 512, 7, 7]           (2,359,296)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-125           [32, 512, 7, 7]           (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-126                  [32, 512, 7, 7]           --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-127                [32, 2048, 7, 7]          (1,048,576)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-128           [32, 2048, 7, 7]          (4,096)\n","‚îÇ    ‚îÇ    ‚îî‚îÄSequential: 3-129            [32, 2048, 7, 7]          (2,101,248)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-130                  [32, 2048, 7, 7]          --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-15                  [32, 2048, 7, 7]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-131                [32, 512, 7, 7]           (1,048,576)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-132           [32, 512, 7, 7]           (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-133                  [32, 512, 7, 7]           --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-134                [32, 512, 7, 7]           (2,359,296)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-135           [32, 512, 7, 7]           (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-136                  [32, 512, 7, 7]           --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-137                [32, 2048, 7, 7]          (1,048,576)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-138           [32, 2048, 7, 7]          (4,096)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-139                  [32, 2048, 7, 7]          --\n","‚îÇ    ‚îî‚îÄBottleneck: 2-16                  [32, 2048, 7, 7]          --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-140                [32, 512, 7, 7]           (1,048,576)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-141           [32, 512, 7, 7]           (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-142                  [32, 512, 7, 7]           --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-143                [32, 512, 7, 7]           (2,359,296)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-144           [32, 512, 7, 7]           (1,024)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-145                  [32, 512, 7, 7]           --\n","‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-146                [32, 2048, 7, 7]          (1,048,576)\n","‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm2d: 3-147           [32, 2048, 7, 7]          (4,096)\n","‚îÇ    ‚îÇ    ‚îî‚îÄReLU: 3-148                  [32, 2048, 7, 7]          --\n","‚îú‚îÄAdaptiveAvgPool2d: 1-9                 [32, 2048, 1, 1]          --\n","‚îú‚îÄLinear: 1-10                           [32, 2]                   4,098\n","==========================================================================================\n","Total params: 23,512,130\n","Trainable params: 4,098\n","Non-trainable params: 23,508,032\n","Total mult-adds (Units.GIGABYTES): 130.79\n","==========================================================================================\n","Input size (MB): 19.27\n","Forward/backward pass size (MB): 5690.36\n","Params size (MB): 94.05\n","Estimated Total Size (MB): 5803.68\n","=========================================================================================="]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## üîπ Step 3: Define Loss Function, Optimizer, and Metrics\n","\n","In this step, we define the core components needed to train the model:\n","\n","- **Loss Function:** Measures the difference between the model's predictions and the true labels. Since this is a binary classification task (fire vs. no fire) with logits (unnormalized outputs), we use `CrossEntropyLoss`, which expects two output logits per image.\n","  \n","- **Optimizer:** Updates model parameters to reduce the loss. We use Adam, which adapts the learning rate for each parameter and typically converges faster than standard SGD.\n","\n","- **Metrics:** During training and validation, we want to track:\n","  - Accuracy: % of correct predictions\n","  - Precision: How many predicted \"fire\" labels are correct\n","  - Recall: How many actual \"fire\" samples were correctly found\n","  - F1 Score: Harmonic mean of precision and recall\n","\n","These metrics help us evaluate how well the model is learning and whether it's favoring one class over the other (e.g. predicting too many false positives or false negatives).\n"],"metadata":{"id":"ik-d8ka7PImf"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# Define loss function\n","# CrossEntropyLoss is appropriate for 2-class classification with logits\n","criterion = nn.CrossEntropyLoss()\n","\n","# Define optimizer ‚Äî only train parameters that require gradients (i.e., not frozen ones)\n","optimizer = optim.Adam(resnet.fc.parameters(), lr=1e-4)\n","\n","# Metrics will be computed manually during validation\n","# These are just placeholders for now (we'll compute them later in the evaluation loop)\n","def calculate_metrics(y_true, y_pred):\n","    \"\"\"\n","    Computes accuracy, precision, recall, and F1 score.\n","    Args:\n","        y_true (Tensor): Ground truth labels (0 or 1)\n","        y_pred (Tensor): Predicted class indices (0 or 1)\n","    Returns:\n","        dict: metric_name ‚Üí value\n","    \"\"\"\n","    y_true = y_true.cpu().numpy()\n","    y_pred = y_pred.cpu().numpy()\n","\n","    return {\n","        'accuracy': accuracy_score(y_true, y_pred),\n","        'precision': precision_score(y_true, y_pred, zero_division=0),\n","        'recall': recall_score(y_true, y_pred, zero_division=0),\n","        'f1': f1_score(y_true, y_pred, zero_division=0)\n","    }\n"],"metadata":{"id":"XACcluDYKSB2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üîπ Step 4: Training and Validation Loop\n","\n","In this step, we implement the main training loop to fine-tune the ResNet-50 model using only the final fully connected layer. We perform training over multiple epochs, and at each epoch we:\n","\n","- Loop over batches from the training DataLoader\n","- Forward pass: compute model predictions\n","- Compute loss using `CrossEntropyLoss`\n","- Backward pass: compute gradients for the final layer only\n","- Update parameters using the Adam optimizer\n","\n","During validation, we:\n","- Disable gradient tracking (for efficiency)\n","- Collect predictions and ground-truth labels across all batches\n","- Compute accuracy, precision, recall, and F1 score using our custom `calculate_metrics` function\n","\n","We also track and print losses and metrics for both training and validation to monitor learning progress.\n"],"metadata":{"id":"hYyXayubQRHd"}},{"cell_type":"code","source":["import time\n","from tqdm import tqdm\n","\n","# ‚úÖ Confirm model is on GPU before starting\n","print(\"üîç Model device:\", next(resnet.parameters()).device)\n","\n","# Training settings\n","num_epochs = 5\n","print_every = 1\n","print_batch_loss = False\n","\n","# For tracking training progress\n","train_losses, val_losses = [], []\n","\n","# ‚úÖ Best model tracking\n","best_f1 = 0.0\n","best_model_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\"\n","\n","# Main training loop\n","for epoch in range(num_epochs):\n","    start_time = time.time()\n","    print(f\"\\nüîÅ Epoch {epoch + 1}/{num_epochs}\")\n","\n","    # ========== Training ==========\n","    resnet.train()\n","    running_loss = 0.0\n","    train_loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"üöÇ Training\", leave=False)\n","\n","    for batch_idx, (images, labels) in train_loop:\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        outputs = resnet(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","        if print_batch_loss and (batch_idx + 1) % 10 == 0:\n","            print(f\"  Batch {batch_idx + 1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n","\n","    avg_train_loss = running_loss / len(train_loader)\n","    train_losses.append(avg_train_loss)\n","\n","    # ========== Validation ==========\n","    resnet.eval()\n","    val_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","\n","    val_loop = tqdm(val_loader, total=len(val_loader), desc=\"üîé Validating\", leave=False)\n","\n","    with torch.no_grad():\n","        for images, labels in val_loop:\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            outputs = resnet(images)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","\n","            preds = torch.argmax(outputs, dim=1)\n","            all_preds.append(preds)\n","            all_labels.append(labels)\n","\n","    avg_val_loss = val_loss / len(val_loader)\n","    val_losses.append(avg_val_loss)\n","\n","    all_preds = torch.cat(all_preds)\n","    all_labels = torch.cat(all_labels)\n","    metrics = calculate_metrics(all_labels, all_preds)\n","\n","    # Print epoch summary\n","    if (epoch + 1) % print_every == 0:\n","        print(f\"‚úÖ Epoch [{epoch + 1}/{num_epochs}] | \"\n","              f\"Train Loss: {avg_train_loss:.4f} | \"\n","              f\"Val Loss: {avg_val_loss:.4f} | \"\n","              f\"Acc: {metrics['accuracy']:.4f} | \"\n","              f\"Precision: {metrics['precision']:.4f} | \"\n","              f\"Recall: {metrics['recall']:.4f} | \"\n","              f\"F1: {metrics['f1']:.4f} | \"\n","              f\"Time: {time.time() - start_time:.1f}s\")\n","\n","    # ‚úÖ Save best model based on F1 score\n","    if metrics['f1'] > best_f1:\n","        best_f1 = metrics['f1']\n","        torch.save(resnet.state_dict(), best_model_path)\n","        print(f\"üíæ New best model saved (F1: {best_f1:.4f}) ‚Üí {best_model_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ULbl4nknQJ4n","executionInfo":{"status":"ok","timestamp":1751405743119,"user_tz":-60,"elapsed":5530467,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"b5a9de1e-eebc-4e66-f091-0db93098b81e"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["üîç Model device: cuda:0\n","\n","üîÅ Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [1/5] | Train Loss: 0.3275 | Val Loss: 0.2780 | Acc: 0.9019 | Precision: 0.8784 | Recall: 0.7384 | F1: 0.8023 | Time: 8001.0s\n","üíæ New best model saved (F1: 0.8023) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n","\n","üîÅ Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [2/5] | Train Loss: 0.2634 | Val Loss: 0.2488 | Acc: 0.9152 | Precision: 0.8760 | Recall: 0.7987 | F1: 0.8356 | Time: 210.2s\n","üíæ New best model saved (F1: 0.8356) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n","\n","üîÅ Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":["                                                                "]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [3/5] | Train Loss: 0.2446 | Val Loss: 0.2448 | Acc: 0.9109 | Precision: 0.9191 | Recall: 0.7341 | F1: 0.8163 | Time: 211.2s\n","\n","üîÅ Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [4/5] | Train Loss: 0.2333 | Val Loss: 0.2263 | Acc: 0.9196 | Precision: 0.8671 | Recall: 0.8288 | F1: 0.8476 | Time: 211.2s\n","üíæ New best model saved (F1: 0.8476) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n","\n","üîÅ Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [5/5] | Train Loss: 0.2257 | Val Loss: 0.2214 | Acc: 0.9222 | Precision: 0.8939 | Recall: 0.8073 | F1: 0.8484 | Time: 212.3s\n","üíæ New best model saved (F1: 0.8484) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n"]}]},{"cell_type":"code","source":["%cd /content/fire-detection-dissertation\n","!git add notebooks/03_train_resnet_real_only.ipynb\n","!git commit -m \"Add full training pipeline for real D-Fire dataset using ResNet-50 with feature extraction and best model saving\"\n","!git push\n"],"metadata":{"id":"p0jtsdvSVTwM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751640943944,"user_tz":-60,"elapsed":821,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"03e76dfb-ad20-44c4-bcd3-974d9c88a623"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/fire-detection-dissertation\n","fatal: pathspec 'notebooks/03_train_resnet_real_only.ipynb' did not match any files\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Gxr5woZV76li"},"execution_count":null,"outputs":[]}]}