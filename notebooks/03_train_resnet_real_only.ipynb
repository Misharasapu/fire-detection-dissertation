{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyNRvSnJezdP9NYZTfWQ2zQV"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Train ResNet-50 on Real Data Only (D-Fire)\n",
    "\n",
    "This notebook implements the baseline fire classification model using only real-world images from the D-Fire dataset. A pretrained ResNet-50 model is fine-tuned to distinguish between fire and non-fire images in a binary classification task.\n",
    "\n",
    "This baseline provides a reference point for later comparisons with models trained on synthetic data and mixed synthetic–real combinations. Performance is evaluated using accuracy, precision, recall, and F1-score on a held-out test set of real images.\n",
    "\n",
    "**Objectives**\n",
    "- Load and split the D-Fire dataset.  \n",
    "- Fine-tune ResNet-50 for binary fire classification.  \n",
    "- Log training metrics and save the best-performing model checkpoint.  \n",
    "- Establish a baseline for comparison with synthetic and mixed-data experiments.  \n"
   ],
   "metadata": {
    "id": "WrwUMilG1gEx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook Setup: Mount Drive and Clone GitHub Repository\n",
    "\n",
    "This cell prepares the environment so the notebook can be reproduced in any new Colab session:\n",
    "\n",
    "- Mount Google Drive to access datasets, secrets, and checkpoints.  \n",
    "- Load the GitHub personal access token from Drive.  \n",
    "- Clone the `fire-detection-dissertation` repository.  \n",
    "- Navigate into the cloned repository directory.  \n",
    "- Configure the Git author identity for commits within the session.  \n",
    "\n",
    "**Note:** This cell must be executed at the beginning of every new Colab session.\n"
   ],
   "metadata": {
    "id": "7t63wO6t1kat"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rsuwo_vTwg-y",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751640783052,
     "user_tz": -60,
     "elapsed": 20106,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "6a660ae3-78fe-4779-dbe5-a4622c92b97d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "/content\n",
      "Cloning into 'fire-detection-dissertation'...\n",
      "remote: Enumerating objects: 30, done.\u001B[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001B[K\n",
      "remote: Compressing objects: 100% (22/22), done.\u001B[K\n",
      "remote: Total 30 (delta 9), reused 23 (delta 6), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (30/30), 176.77 KiB | 16.07 MiB/s, done.\n",
      "Resolving deltas: 100% (9/9), done.\n",
      "/content/fire-detection-dissertation\n"
     ]
    }
   ],
   "source": [
    "# Notebook setup: mount Google Drive and clone the GitHub repository\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "if not os.path.ismount(\"/content/drive\"):\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "# 2. Load the GitHub personal access token from Drive\n",
    "token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n",
    "with open(token_path, \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "# 3. Clone the GitHub repository (force a fresh copy each session)\n",
    "username = \"Misharasapu\"\n",
    "repo = \"fire-detection-dissertation\"\n",
    "clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n",
    "repo_path = f\"/content/{repo}\"\n",
    "\n",
    "# Remove any existing clone to avoid conflicts\n",
    "!rm -rf {repo_path}\n",
    "\n",
    "# Clone the repository and move into the directory\n",
    "%cd /content\n",
    "!git clone {clone_url}\n",
    "%cd {repo}\n",
    "\n",
    "# 4. Configure Git author identity (required in Colab sessions)\n",
    "!git config --global user.name \"Misharasapu\"\n",
    "!git config --global user.email \"misharasapu@gmail.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Load and Split the Real Dataset (Train/Validation Only)\n",
    "\n",
    "In this step, the D-Fire dataset is loaded using the `FireClassificationDataset` class and divided into training and validation subsets. The separate test set remains untouched and will be reserved for final evaluation after all experiments are complete.\n",
    "\n",
    "Each image in D-Fire is paired with a YOLO-style `.txt` label file. The dataset loader automatically converts these annotations into binary fire/no-fire labels based on the class ID rules.\n",
    "\n",
    "The dataset is split into training and validation sets using an 80/20 ratio with a fixed random seed to ensure reproducibility. Both subsets are wrapped in PyTorch `DataLoader` objects to support batching and shuffling during training.\n",
    "\n",
    "This step ensures the model is trained on real-world examples while maintaining a consistent split strategy.\n"
   ],
   "metadata": {
    "id": "vP3StHLb2Oq-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from utils.fire_classification_dataset import FireClassificationDataset\n",
    "\n",
    "# Define image transforms: resize to 224x224 and convert to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Paths to D-Fire training images and YOLO label files\n",
    "image_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/images\"\n",
    "label_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/labels\"\n",
    "\n",
    "# Load the full dataset\n",
    "full_dataset = FireClassificationDataset(\n",
    "    image_dir=image_dir,\n",
    "    label_dir=label_dir,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Split dataset into training and validation subsets (80/20 split)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "# Use a fixed seed for reproducibility\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "# Wrap subsets in DataLoaders for batching and shuffling\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Confirm dataset sizes\n",
    "print(f\"Total samples in full dataset: {len(full_dataset)}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "# Preview one batch from the training DataLoader\n",
    "train_batch = next(iter(train_loader))\n",
    "images, labels = train_batch\n",
    "\n",
    "print(f\"\\nBatch shape (images): {images.shape}\")   # Expected: (32, 3, 224, 224)\n",
    "print(f\"Batch shape (labels): {labels.shape}\")     # Expected: (32,)\n",
    "print(f\"Sample labels: {labels.tolist()}\")         # Quick look at label distribution\n"
   ],
   "metadata": {
    "id": "xt7XDeWz1pTZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751393732144,
     "user_tz": -60,
     "elapsed": 188990,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "2af67731-e4bb-4c1f-bc2b-8d60720f5ad9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total samples in full dataset: 17222\n",
      "Training samples: 13777\n",
      "Validation samples: 3445\n",
      "\n",
      "Batch shape (images): torch.Size([32, 3, 224, 224])\n",
      "Batch shape (labels): torch.Size([32])\n",
      "Sample labels: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Load and Modify ResNet-50 for Binary Classification\n",
    "\n",
    "In this step, a pretrained ResNet-50 model is loaded from the `torchvision.models` library and adapted for binary fire classification (fire vs. no fire).\n",
    "\n",
    "By default, ResNet-50 is trained on ImageNet with 1000 output classes. The model is adapted as follows:\n",
    "- Load the pretrained ResNet-50 with ImageNet weights.  \n",
    "- Freeze the convolutional backbone to retain pretrained features (this can later be unfrozen for fine-tuning).  \n",
    "- Replace the final fully connected (FC) layer with a new linear layer for two output classes.  \n",
    "\n",
    "This transfer learning approach leverages feature representations learned from large-scale natural image data while adapting the classifier head for the fire detection task.\n"
   ],
   "metadata": {
    "id": "KYBVaFoyIV3y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "# Load a ResNet-50 pretrained on ImageNet\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "\n",
    "# Optionally freeze all backbone layers (only classification head will be trained)\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace the final fully connected layer with a binary classifier\n",
    "in_features = resnet.fc.in_features  # Expected: 2048\n",
    "resnet.fc = nn.Linear(in_features, 2)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = resnet.to(device)\n",
    "\n",
    "# Display model architecture (optional)\n",
    "print(resnet)\n",
    "\n",
    "# Optional: use torchinfo for a more structured summary\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "# Show summary for a batch size of 32, 3-channel input at 224×224 resolution\n",
    "summary(resnet, input_size=(32, 3, 224, 224))\n"
   ],
   "metadata": {
    "id": "BxZzZI3N5uX_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751394061500,
     "user_tz": -60,
     "elapsed": 8087,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "b86cdeeb-df9a-4d0e-ae15-9f09e9c44f18"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      ")\n",
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [32, 2]                   --\n",
       "├─Conv2d: 1-1                            [32, 64, 112, 112]        (9,408)\n",
       "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        (128)\n",
       "├─ReLU: 1-3                              [32, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [32, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [32, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-1                   [32, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          (4,096)\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-7                  [32, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 256, 56, 56]         (512)\n",
       "│    │    └─Sequential: 3-9              [32, 256, 56, 56]         (16,896)\n",
       "│    │    └─ReLU: 3-10                   [32, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-2                   [32, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-11                 [32, 64, 56, 56]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-12            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-13                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-14                 [32, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-15            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-16                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-17                 [32, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-18            [32, 256, 56, 56]         (512)\n",
       "│    │    └─ReLU: 3-19                   [32, 256, 56, 56]         --\n",
       "│    └─Bottleneck: 2-3                   [32, 256, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-20                 [32, 64, 56, 56]          (16,384)\n",
       "│    │    └─BatchNorm2d: 3-21            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-22                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-23                 [32, 64, 56, 56]          (36,864)\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 64, 56, 56]          (128)\n",
       "│    │    └─ReLU: 3-25                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 56, 56]         (16,384)\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 56, 56]         (512)\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 56, 56]         --\n",
       "├─Sequential: 1-6                        [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-4                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-29                 [32, 128, 56, 56]         (32,768)\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 128, 56, 56]         (256)\n",
       "│    │    └─ReLU: 3-31                   [32, 128, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-32                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-33            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-34                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-35                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-36            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─Sequential: 3-37             [32, 512, 28, 28]         (132,096)\n",
       "│    │    └─ReLU: 3-38                   [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-5                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-39                 [32, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-41                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-42                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-44                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-45                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-46            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-47                   [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-6                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-48                 [32, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-49            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-50                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-51                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-52            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-53                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-54                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-55            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-56                   [32, 512, 28, 28]         --\n",
       "│    └─Bottleneck: 2-7                   [32, 512, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-57                 [32, 128, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-58            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-59                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-60                 [32, 128, 28, 28]         (147,456)\n",
       "│    │    └─BatchNorm2d: 3-61            [32, 128, 28, 28]         (256)\n",
       "│    │    └─ReLU: 3-62                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-63                 [32, 512, 28, 28]         (65,536)\n",
       "│    │    └─BatchNorm2d: 3-64            [32, 512, 28, 28]         (1,024)\n",
       "│    │    └─ReLU: 3-65                   [32, 512, 28, 28]         --\n",
       "├─Sequential: 1-7                        [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-8                   [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-66                 [32, 256, 28, 28]         (131,072)\n",
       "│    │    └─BatchNorm2d: 3-67            [32, 256, 28, 28]         (512)\n",
       "│    │    └─ReLU: 3-68                   [32, 256, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-69                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-70            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-71                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-72                 [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-73            [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─Sequential: 3-74             [32, 1024, 14, 14]        (526,336)\n",
       "│    │    └─ReLU: 3-75                   [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-9                   [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-76                 [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-77            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-78                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-79                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-80            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-81                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-82                 [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-83            [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-84                   [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-10                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-85                 [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-86            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-87                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-88                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-89            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-90                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-91                 [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-92            [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-93                   [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-11                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-94                 [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-95            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-96                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-97                 [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-98            [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-99                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-100                [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-101           [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-102                  [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-12                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-103                [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-104           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-105                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-106                [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-107           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-108                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-109                [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-110           [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-111                  [32, 1024, 14, 14]        --\n",
       "│    └─Bottleneck: 2-13                  [32, 1024, 14, 14]        --\n",
       "│    │    └─Conv2d: 3-112                [32, 256, 14, 14]         (262,144)\n",
       "│    │    └─BatchNorm2d: 3-113           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-114                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-115                [32, 256, 14, 14]         (589,824)\n",
       "│    │    └─BatchNorm2d: 3-116           [32, 256, 14, 14]         (512)\n",
       "│    │    └─ReLU: 3-117                  [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-118                [32, 1024, 14, 14]        (262,144)\n",
       "│    │    └─BatchNorm2d: 3-119           [32, 1024, 14, 14]        (2,048)\n",
       "│    │    └─ReLU: 3-120                  [32, 1024, 14, 14]        --\n",
       "├─Sequential: 1-8                        [32, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-14                  [32, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-121                [32, 512, 14, 14]         (524,288)\n",
       "│    │    └─BatchNorm2d: 3-122           [32, 512, 14, 14]         (1,024)\n",
       "│    │    └─ReLU: 3-123                  [32, 512, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-124                [32, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-125           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-126                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-127                [32, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-128           [32, 2048, 7, 7]          (4,096)\n",
       "│    │    └─Sequential: 3-129            [32, 2048, 7, 7]          (2,101,248)\n",
       "│    │    └─ReLU: 3-130                  [32, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-15                  [32, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-131                [32, 512, 7, 7]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-132           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-133                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-134                [32, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-135           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-136                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-137                [32, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-138           [32, 2048, 7, 7]          (4,096)\n",
       "│    │    └─ReLU: 3-139                  [32, 2048, 7, 7]          --\n",
       "│    └─Bottleneck: 2-16                  [32, 2048, 7, 7]          --\n",
       "│    │    └─Conv2d: 3-140                [32, 512, 7, 7]           (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-141           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-142                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-143                [32, 512, 7, 7]           (2,359,296)\n",
       "│    │    └─BatchNorm2d: 3-144           [32, 512, 7, 7]           (1,024)\n",
       "│    │    └─ReLU: 3-145                  [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-146                [32, 2048, 7, 7]          (1,048,576)\n",
       "│    │    └─BatchNorm2d: 3-147           [32, 2048, 7, 7]          (4,096)\n",
       "│    │    └─ReLU: 3-148                  [32, 2048, 7, 7]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [32, 2048, 1, 1]          --\n",
       "├─Linear: 1-10                           [32, 2]                   4,098\n",
       "==========================================================================================\n",
       "Total params: 23,512,130\n",
       "Trainable params: 4,098\n",
       "Non-trainable params: 23,508,032\n",
       "Total mult-adds (Units.GIGABYTES): 130.79\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 5690.36\n",
       "Params size (MB): 94.05\n",
       "Estimated Total Size (MB): 5803.68\n",
       "=========================================================================================="
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Define Loss Function, Optimizer, and Metrics\n",
    "\n",
    "In this step, the core components for model training are defined:\n",
    "\n",
    "- **Loss function:** `CrossEntropyLoss` is used, as the task is binary classification with logits. The model outputs two logits per image (fire vs. no fire), which are compared against integer class labels.  \n",
    "- **Optimizer:** Adam is chosen for parameter updates, as it adapts learning rates per parameter and typically converges faster than standard SGD. Only parameters with `requires_grad=True` (i.e., unfrozen layers) are updated.  \n",
    "- **Metrics:** To monitor performance during training and validation, the following are tracked:  \n",
    "  - Accuracy — proportion of correct predictions.  \n",
    "  - Precision — proportion of predicted “fire” samples that are correct.  \n",
    "  - Recall — proportion of actual “fire” samples correctly identified.  \n",
    "  - F1 Score — harmonic mean of precision and recall.  \n",
    "\n",
    "Tracking these metrics helps evaluate whether the model is balanced across classes and highlights any tendency toward false positives or false negatives.\n"
   ],
   "metadata": {
    "id": "ik-d8ka7PImf"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Loss function: suitable for binary classification with logits\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer: update only parameters that require gradients (unfrozen layers)\n",
    "optimizer = optim.Adam(resnet.fc.parameters(), lr=1e-4)\n",
    "\n",
    "# Metric computation helper (used during validation and testing)\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute accuracy, precision, recall, and F1 score.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : Tensor\n",
    "        Ground truth labels (0 or 1).\n",
    "    y_pred : Tensor\n",
    "        Predicted class indices (0 or 1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing accuracy, precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    y_true = y_true.cpu().numpy()\n",
    "    y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"f1\": f1_score(y_true, y_pred, zero_division=0),\n",
    "    }\n"
   ],
   "metadata": {
    "id": "XACcluDYKSB2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Training and Validation Loop\n",
    "\n",
    "This step implements the main training loop to fine-tune ResNet-50 using the final fully connected layer. For each epoch, the procedure is:\n",
    "\n",
    "- Iterate over batches from the training `DataLoader`.  \n",
    "- Forward pass to obtain predictions.  \n",
    "- Compute loss using `CrossEntropyLoss`.  \n",
    "- Backward pass to compute gradients for the trainable parameters.  \n",
    "- Update parameters using the Adam optimizer.\n",
    "\n",
    "During validation:\n",
    "- Disable gradient tracking for efficiency.  \n",
    "- Accumulate predictions and ground-truth labels across all batches.  \n",
    "- Compute accuracy, precision, recall, and F1 score via `calculate_metrics`.\n",
    "\n",
    "Training and validation losses, along with the metrics, are printed each epoch. The best model (by validation F1) is saved to disk.\n"
   ],
   "metadata": {
    "id": "hYyXayubQRHd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Confirm model device before starting\n",
    "print(\"Model device:\", next(resnet.parameters()).device)\n",
    "\n",
    "# Training settings\n",
    "num_epochs = 5\n",
    "print_every = 1\n",
    "print_batch_loss = False\n",
    "\n",
    "# Track loss curves\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "# Best model tracking\n",
    "best_f1 = 0.0\n",
    "best_model_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\"\n",
    "\n",
    "# Main training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # ========= Training =========\n",
    "    resnet.train()\n",
    "    running_loss = 0.0\n",
    "    train_loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=\"Training\", leave=False)\n",
    "\n",
    "    for batch_idx, (images, labels) in train_loop:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = resnet(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if print_batch_loss and (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"  Batch {batch_idx + 1}/{len(train_loader)} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # ========= Validation =========\n",
    "    resnet.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    val_loop = tqdm(val_loader, total=len(val_loader), desc=\"Validating\", leave=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loop:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = resnet(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    metrics = calculate_metrics(all_labels, all_preds)\n",
    "\n",
    "    # Epoch summary\n",
    "    if (epoch + 1) % print_every == 0:\n",
    "        duration = time.time() - start_time\n",
    "        print(\n",
    "            f\"Epoch [{epoch + 1}/{num_epochs}] | \"\n",
    "            f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f} | \"\n",
    "            f\"Acc: {metrics['accuracy']:.4f} | \"\n",
    "            f\"Precision: {metrics['precision']:.4f} | \"\n",
    "            f\"Recall: {metrics['recall']:.4f} | \"\n",
    "            f\"F1: {metrics['f1']:.4f} | \"\n",
    "            f\"Time: {duration:.1f}s\"\n",
    "        )\n",
    "\n",
    "    # Save best model based on F1 score\n",
    "    if metrics[\"f1\"] > best_f1:\n",
    "        best_f1 = metrics[\"f1\"]\n",
    "        torch.save(resnet.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved (F1: {best_f1:.4f}) → {best_model_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULbl4nknQJ4n",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751405743119,
     "user_tz": -60,
     "elapsed": 5530467,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "b5a9de1e-eebc-4e66-f091-0db93098b81e"
   },
   "execution_count": null,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Model device: cuda:0\n",
      "\n",
      "🔁 Epoch 1/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [1/5] | Train Loss: 0.3275 | Val Loss: 0.2780 | Acc: 0.9019 | Precision: 0.8784 | Recall: 0.7384 | F1: 0.8023 | Time: 8001.0s\n",
      "💾 New best model saved (F1: 0.8023) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n",
      "\n",
      "🔁 Epoch 2/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [2/5] | Train Loss: 0.2634 | Val Loss: 0.2488 | Acc: 0.9152 | Precision: 0.8760 | Recall: 0.7987 | F1: 0.8356 | Time: 210.2s\n",
      "💾 New best model saved (F1: 0.8356) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n",
      "\n",
      "🔁 Epoch 3/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [3/5] | Train Loss: 0.2446 | Val Loss: 0.2448 | Acc: 0.9109 | Precision: 0.9191 | Recall: 0.7341 | F1: 0.8163 | Time: 211.2s\n",
      "\n",
      "🔁 Epoch 4/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [4/5] | Train Loss: 0.2333 | Val Loss: 0.2263 | Acc: 0.9196 | Precision: 0.8671 | Recall: 0.8288 | F1: 0.8476 | Time: 211.2s\n",
      "💾 New best model saved (F1: 0.8476) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n",
      "\n",
      "🔁 Epoch 5/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [5/5] | Train Loss: 0.2257 | Val Loss: 0.2214 | Acc: 0.9222 | Precision: 0.8939 | Recall: 0.8073 | F1: 0.8484 | Time: 212.3s\n",
      "💾 New best model saved (F1: 0.8484) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_best.pt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%cd /content/fire-detection-dissertation\n",
    "!git add notebooks/03_train_resnet_real_only.ipynb\n",
    "!git commit -m \"Add full training pipeline for real D-Fire dataset using ResNet-50 with feature extraction and best model saving\"\n",
    "!git push\n"
   ],
   "metadata": {
    "id": "p0jtsdvSVTwM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1751640943944,
     "user_tz": -60,
     "elapsed": 821,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "03e76dfb-ad20-44c4-bcd3-974d9c88a623"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/fire-detection-dissertation\n",
      "fatal: pathspec 'notebooks/03_train_resnet_real_only.ipynb' did not match any files\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "Everything up-to-date\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Gxr5woZV76li"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
