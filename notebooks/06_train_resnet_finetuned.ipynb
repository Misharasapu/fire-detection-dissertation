{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhCjkmLwBwOFAoS7aAmSB1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ğŸ”§ Fine-Tuning ResNet-50 on Real, Synthetic, and Mixed Fire Datasets\n","\n","This notebook fine-tunes ResNet-50 classification models using three dataset compositions:\n","- 100% real images from the D-Fire dataset\n","- 100% synthetic images from the Yunnan UE5-generated dataset\n","- 50/50 mixed composition using the `FireClassificationMixedDataset` class\n","\n","The goal is to assess whether fine-tuning improves model performance compared to feature extraction, especially when only limited real data is available. Fine-tuning is performed by unfreezing the final ResNet-50 block (`layer4`) and fully connected layer (`fc`), while keeping earlier layers frozen.\n","\n","Each model is trained for 5 epochs using the same training loop defined in `train_model.py`, with validation on the held-out D-Fire validation set. Results will be compared directly to their frozen counterparts from Phase 1.\n"],"metadata":{"id":"s1pQkO-uOy1J"}},{"cell_type":"markdown","source":["## ğŸ“¦ Notebook Setup: Mount Drive & Clone GitHub Repo\n","\n","This cell ensures the notebook is reproducible in any new Colab session by:\n","\n","- Mounting your Google Drive (to access datasets, secrets, and checkpoints)\n","- Loading your GitHub token from Drive\n","- Cloning the fire-detection-dissertation repository\n","- Navigating into the correct folder\n","- Setting Git identity for future commits\n","\n","âš ï¸ **Note:** This cell must be run every time you open this notebook in a new Colab session.\n"],"metadata":{"id":"S9eIgnXxOye4"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8Wb3b_UN773","executionInfo":{"status":"ok","timestamp":1753518976657,"user_tz":-60,"elapsed":20558,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"2ea7227e-b653-46cb-f031-ad7a1ca5718d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content\n","Cloning into 'fire-detection-dissertation'...\n","remote: Enumerating objects: 100, done.\u001b[K\n","remote: Counting objects: 100% (100/100), done.\u001b[K\n","remote: Compressing objects: 100% (78/78), done.\u001b[K\n","remote: Total 100 (delta 45), reused 71 (delta 20), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (100/100), 4.08 MiB | 9.09 MiB/s, done.\n","Resolving deltas: 100% (45/45), done.\n","/content/fire-detection-dissertation\n"]}],"source":["# ğŸ”§ Minimal Colab setup for any working notebook\n","\n","# 1. Mount Google Drive\n","import os\n","from google.colab import drive\n","if not os.path.ismount(\"/content/drive\"):\n","    drive.mount(\"/content/drive\")\n","\n","# 2. Load GitHub token securely from Drive\n","token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n","with open(token_path, \"r\") as f:\n","    token = f.read().strip()\n","\n","# 3. Clone the GitHub repo (force fresh clone for safety)\n","username = \"Misharasapu\"\n","repo = \"fire-detection-dissertation\"\n","clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n","repo_path = f\"/content/{repo}\"\n","\n","# Optional: Remove old clone (safe to rerun)\n","!rm -rf {repo_path}\n","\n","# Clone fresh and move into the repo\n","%cd /content\n","!git clone {clone_url}\n","%cd {repo}\n","\n","# 4. Set Git identity (required in Colab sessions)\n","!git config --global user.name \"Misharasapu\"\n","!git config --global user.email \"misharasapu@gmail.com\"\n"]},{"cell_type":"markdown","source":["## ğŸ§© Step 1: Define Dataset Type, Paths, and Model Filenames\n","\n","In this step, we define the training configuration for each model to be fine-tuned. Three dataset types are used:\n","\n","- ğŸ”µ `real`: 100% real images (D-Fire)\n","- ğŸŸ  `synthetic`: 100% synthetic images (Yunnan UE5)\n","- ğŸŸ£ `mixed`: 50% synthetic, 50% real\n","\n","We also define model filenames dynamically and ensure reproducibility with a fixed random seed. The total number of training samples is kept constant for the mixed dataset (5,260), and filenames are structured to reflect the data composition used during training.\n"],"metadata":{"id":"Ylo-h99xWD05"}},{"cell_type":"code","source":["import os\n","import random\n","import torch\n","import numpy as np\n","\n","# ğŸ”§ Adjustable configuration\n","syn_ratio = 0.50                     # Used only for the mixed dataset\n","total_samples = 5260                # Fixed total sample size for mixed dataset\n","\n","# ğŸ—‚ï¸ Paths to training data\n","real_image_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/images\"\n","real_label_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/labels\"\n","\n","syn_image_dir  = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/yunnan/synthetic_all/images\"\n","syn_label_dir  = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/yunnan/synthetic_all/labels\"\n","\n","# ğŸ§  Model filenames based on dataset type\n","model_paths = {\n","    \"real\":    \"resnet_real_100_ft.pt\",\n","    \"synthetic\": \"resnet_synthetic_100_ft.pt\",\n","    \"mixed\":   f\"resnet_mixed_{int(syn_ratio*100)}syn_{int((1-syn_ratio)*100)}real_ft.pt\"\n","}\n","\n","# âœ… Set random seed for reproducibility\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n"],"metadata":{"id":"DN_Bsc3vPRzr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ğŸ§¼ Step 2: Define Image Transformations\n","\n","We define the image transformation pipeline used across all datasets. Images are resized to 224Ã—224, normalized to ImageNet statistics, and converted to PyTorch tensors.\n","\n","This ensures compatibility with the input format expected by ResNet-50, which was pretrained on ImageNet.\n"],"metadata":{"id":"BU-4MJwtcSa9"}},{"cell_type":"code","source":["from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n"],"metadata":{"id":"fXX6CpoAZLAl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## âš™ï¸ Step 3: Load Dataset, Pretrained Model, and Configure Fine-Tuning\n","\n","Based on the selected training mode (`\"real\"`, `\"synthetic\"`, or `\"mixed\"`), we perform the following:\n","\n","1. Load the appropriate dataset class with the predefined transform:\n","   - `FireClassificationDataset` for real images (D-Fire)\n","   - `FireClassificationSyntheticDataset` for synthetic images (Yunnan UE5)\n","   - `FireClassificationMixedDataset` for a fixed-ratio combination of both\n","\n","2. Split the full dataset into training and validation subsets using an 80/20 split with a fixed random seed (`seed=42`) to ensure reproducibility.\n","\n","3. Load the corresponding Phase 1 model (`*_100.pt`), which was trained using feature extraction (frozen base, trained `fc` layer only).\n","\n","4. Construct the Adam optimizer using only the parameters marked with `requires_grad=True`. Fine-tuning will be handled automatically inside the `train_model()` helper by unfreezing `layer4` and `fc` when `fine_tune=True`.\n","\n","This setup ensures consistent dataset usage and training conditions across all modes, and enables us to isolate the impact of fine-tuning deeper convolutional layers on classification performance.\n"],"metadata":{"id":"DN8PurielUdY"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader, random_split\n","from torchvision import models\n","from torch import nn, optim\n","from utils.fire_classification_dataset import (\n","    FireClassificationDataset,\n","    FireClassificationSyntheticDataset,\n","    FireClassificationMixedDataset\n",")\n","\n","# ğŸ”˜ SELECT WHICH MODEL TO TRAIN\n","selected_mode = \"real\"  # Options: \"real\", \"synthetic\", \"mixed\"\n","print(f\"\\nğŸ“¦ Selected mode: {selected_mode.upper()}\")\n","\n","# ğŸ–¥ï¸ Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","using_gpu = torch.cuda.is_available()\n","print(f\"ğŸ–¥ï¸ Using device: {device} ({'GPU enabled' if using_gpu else 'CPU only'})\")\n","\n","# âœ… Training parameters\n","batch_size = 32\n","num_epochs = 5\n","learning_rate = 1e-4\n","print(f\"ğŸ“Œ Training config â†’ Batch size: {batch_size}, Epochs: {num_epochs}, LR: {learning_rate}\")\n","\n","# âœ… Load dataset based on selected mode\n","if selected_mode == \"real\":\n","    print(\"ğŸ”¹ Loading 100% real dataset (D-Fire)...\")\n","    full_dataset = FireClassificationDataset(real_image_dir, real_label_dir, transform=transform)\n","    pretrained_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100.pt\"\n","\n","elif selected_mode == \"synthetic\":\n","    print(\"ğŸ”¸ Loading 100% synthetic dataset (Yunnan)...\")\n","    full_dataset = FireClassificationSyntheticDataset(syn_image_dir, syn_label_dir, transform=transform)\n","    pretrained_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_synthetic_100.pt\"\n","\n","elif selected_mode == \"mixed\":\n","    print(\"ğŸŸ£ Loading 50/50 mixed dataset (Real + Synthetic)...\")\n","    print(f\"   â†’ Synthetic ratio: {syn_ratio}, Total samples: {total_samples}\")\n","    full_dataset = FireClassificationMixedDataset(\n","        real_image_dir, real_label_dir,\n","        syn_image_dir, syn_label_dir,\n","        syn_ratio=syn_ratio,\n","        total_samples=total_samples,\n","        transform=transform\n","    )\n","    pretrained_path = f\"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_mixed_{int(syn_ratio*100)}syn_{int((1-syn_ratio)*100)}real.pt\"\n","\n","else:\n","    raise ValueError(\"âŒ Invalid mode. Choose from: 'real', 'synthetic', or 'mixed'.\")\n","\n","# âœ… Split into train and validation subsets (80/20)\n","train_ratio = 0.8\n","train_size = int(train_ratio * len(full_dataset))\n","val_size = len(full_dataset) - train_size\n","generator = torch.Generator().manual_seed(42)\n","\n","train_data, val_data = random_split(full_dataset, [train_size, val_size], generator=generator)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","\n","print(f\"ğŸ“Š Dataset split â†’ Train: {train_size}, Validation: {val_size}\")\n","\n","# âœ… Load pretrained model from Phase 1 (CPU-safe)\n","print(f\"\\nğŸ”§ Loading pretrained Phase 1 model: {pretrained_path}\")\n","model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, 2)\n","model.load_state_dict(torch.load(pretrained_path, map_location=device))\n","model = model.to(device)\n","print(\"âœ… Model loaded and moved to device.\")\n","\n","# âœ… Construct optimizer using only trainable parameters\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n","print(\"ğŸ› ï¸ Optimizer configured (Adam, fine-tuning mode).\")\n","\n","# âœ… Set save path for fine-tuned model\n","save_path = f\"/content/drive/MyDrive/fire-detection-dissertation/models/{model_paths[selected_mode]}\"\n","print(f\"ğŸ’¾ Fine-tuned model will be saved to: {save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pceHNfeakfCl","executionInfo":{"status":"ok","timestamp":1753474578380,"user_tz":-60,"elapsed":6432,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"2604e491-ec41-4fbe-f336-4370ba7041fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ“¦ Selected mode: REAL\n","ğŸ–¥ï¸ Using device: cpu (CPU only)\n","ğŸ“Œ Training config â†’ Batch size: 32, Epochs: 5, LR: 0.0001\n","ğŸ”¹ Loading 100% real dataset (D-Fire)...\n","ğŸ“Š Dataset split â†’ Train: 13777, Validation: 3445\n","\n","ğŸ”§ Loading pretrained Phase 1 model: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100.pt\n","âœ… Model loaded and moved to device.\n","ğŸ› ï¸ Optimizer configured (Adam, fine-tuning mode).\n","ğŸ’¾ Fine-tuned model will be saved to: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100_ft.pt\n"]}]},{"cell_type":"markdown","source":["## ğŸ” Step 4: Train the Fine-Tuned Model (layer4 + fc)\n","\n","In this step, we begin training the selected model using the `train_model()` helper function.\n","\n","- `fine_tune=True` ensures that both `layer4` and `fc` are unfrozen and trained.\n","- The model weights are initialized from the Phase 1 checkpoint (trained with feature extraction).\n","- The model will be trained for 5 additional epochs using the same dataset composition as in Phase 1.\n","- Results will be printed at the end of each epoch and the best-performing model (by F1 score) will be saved to the specified path.\n"],"metadata":{"id":"TLVcdlNOq8SY"}},{"cell_type":"code","source":["from utils.train_model import train_model\n","from torch.nn import CrossEntropyLoss\n","\n","# âœ… Define loss function\n","criterion = CrossEntropyLoss()\n","\n","# âœ… Start training (with fine-tuning)\n","train_losses, val_losses = train_model(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=num_epochs,\n","    device=device,\n","    save_path=save_path,\n","    fine_tune=True,  #  Fine-tune layer4 + fc\n","    print_every=1,\n","    print_batch_loss=False\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBIaToEXoNgV","outputId":"0fdf15f5-5bdd-44b7-f124-867073b02848","executionInfo":{"status":"ok","timestamp":1753509992545,"user_tz":-60,"elapsed":21864650,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}}},"execution_count":6,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","ğŸ” Model device: cpu\n","ğŸ”§ Fine-tuning mode: Unfreezing layer4 and fc...\n","ğŸ“Š Trainable parameters: 14968834\n","\n","ğŸ” Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["âœ… Epoch [1/5] | Train Loss: 0.1364 | Val Loss: 0.0884 | Acc: 0.9710 | Precision: 0.9471 | Recall: 0.9451 | F1: 0.9461 | Time: 21044.6s\n","ğŸ’¾ New best model saved (F1: 0.9461) â†’ /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100_ft.pt\n","\n","ğŸ” Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["âœ… Epoch [2/5] | Train Loss: 0.0546 | Val Loss: 0.1140 | Acc: 0.9663 | Precision: 0.9161 | Recall: 0.9634 | F1: 0.9391 | Time: 3536.8s\n","\n","ğŸ” Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["âœ… Epoch [3/5] | Train Loss: 0.0279 | Val Loss: 0.1315 | Acc: 0.9669 | Precision: 0.9605 | Recall: 0.9150 | F1: 0.9372 | Time: 3527.7s\n","\n","ğŸ” Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["âœ… Epoch [4/5] | Train Loss: 0.0226 | Val Loss: 0.1044 | Acc: 0.9724 | Precision: 0.9523 | Recall: 0.9451 | F1: 0.9487 | Time: 3575.8s\n","ğŸ’¾ New best model saved (F1: 0.9487) â†’ /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100_ft.pt\n","\n","ğŸ” Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["                                                                "]},{"output_type":"stream","name":"stdout","text":["âœ… Epoch [5/5] | Train Loss: 0.0198 | Val Loss: 0.1169 | Acc: 0.9713 | Precision: 0.9621 | Recall: 0.9300 | F1: 0.9458 | Time: 3717.3s\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"code","source":["# âœ… 1. Navigate to the Git-tracked repo folder\n","%cd /content/fire-detection-dissertation\n","\n","# âœ… 2. Move the notebook from Drive into the repo so Git can track it\n","!mv /content/drive/MyDrive/fire-detection-dissertation/notebooks/06_train_resnet_finetuned.ipynb /content/fire-detection-dissertation/notebooks/\n","\n","# Optional: confirm it's now inside the repo\n","!ls notebooks/\n","\n","# âœ… 3. Stage the notebook for commit\n","!git add notebooks/06_train_resnet_finetuned.ipynb\n","\n","# âœ… 4. Commit with a message\n","!git commit -m \"Added Phase 2 fine-tuning notebook with modular support for real/synthetic/mixed models\n","\"\n","\n","# âœ… 5. Push to GitHub\n","!git push\n"],"metadata":{"id":"BU7ALzPB5JXM"},"execution_count":null,"outputs":[]}]}