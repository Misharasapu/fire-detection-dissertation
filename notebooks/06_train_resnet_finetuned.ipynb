{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhCjkmLwBwOFAoS7aAmSB1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# üîß Fine-Tuning ResNet-50 on Real, Synthetic, and Mixed Fire Datasets\n","\n","This notebook fine-tunes ResNet-50 classification models using three dataset compositions:\n","- 100% real images from the D-Fire dataset\n","- 100% synthetic images from the Yunnan UE5-generated dataset\n","- 50/50 mixed composition using the `FireClassificationMixedDataset` class\n","\n","The goal is to assess whether fine-tuning improves model performance compared to feature extraction, especially when only limited real data is available. Fine-tuning is performed by unfreezing the final ResNet-50 block (`layer4`) and fully connected layer (`fc`), while keeping earlier layers frozen.\n","\n","Each model is trained for 5 epochs using the same training loop defined in `train_model.py`, with validation on the held-out D-Fire validation set. Results will be compared directly to their frozen counterparts from Phase 1.\n"],"metadata":{"id":"s1pQkO-uOy1J"}},{"cell_type":"markdown","source":["## üì¶ Notebook Setup: Mount Drive & Clone GitHub Repo\n","\n","This cell ensures the notebook is reproducible in any new Colab session by:\n","\n","- Mounting your Google Drive (to access datasets, secrets, and checkpoints)\n","- Loading your GitHub token from Drive\n","- Cloning the fire-detection-dissertation repository\n","- Navigating into the correct folder\n","- Setting Git identity for future commits\n","\n","‚ö†Ô∏è **Note:** This cell must be run every time you open this notebook in a new Colab session.\n"],"metadata":{"id":"S9eIgnXxOye4"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v8Wb3b_UN773","executionInfo":{"status":"ok","timestamp":1753518976657,"user_tz":-60,"elapsed":20558,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"2ea7227e-b653-46cb-f031-ad7a1ca5718d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content\n","Cloning into 'fire-detection-dissertation'...\n","remote: Enumerating objects: 100, done.\u001b[K\n","remote: Counting objects: 100% (100/100), done.\u001b[K\n","remote: Compressing objects: 100% (78/78), done.\u001b[K\n","remote: Total 100 (delta 45), reused 71 (delta 20), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (100/100), 4.08 MiB | 9.09 MiB/s, done.\n","Resolving deltas: 100% (45/45), done.\n","/content/fire-detection-dissertation\n"]}],"source":["# üîß Minimal Colab setup for any working notebook\n","\n","# 1. Mount Google Drive\n","import os\n","from google.colab import drive\n","if not os.path.ismount(\"/content/drive\"):\n","    drive.mount(\"/content/drive\")\n","\n","# 2. Load GitHub token securely from Drive\n","token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n","with open(token_path, \"r\") as f:\n","    token = f.read().strip()\n","\n","# 3. Clone the GitHub repo (force fresh clone for safety)\n","username = \"Misharasapu\"\n","repo = \"fire-detection-dissertation\"\n","clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n","repo_path = f\"/content/{repo}\"\n","\n","# Optional: Remove old clone (safe to rerun)\n","!rm -rf {repo_path}\n","\n","# Clone fresh and move into the repo\n","%cd /content\n","!git clone {clone_url}\n","%cd {repo}\n","\n","# 4. Set Git identity (required in Colab sessions)\n","!git config --global user.name \"Misharasapu\"\n","!git config --global user.email \"misharasapu@gmail.com\"\n"]},{"cell_type":"markdown","source":["## üß© Step 1: Define Dataset Type, Paths, and Model Filenames\n","\n","In this step, we define the training configuration for each model to be fine-tuned. Three dataset types are used:\n","\n","- üîµ `real`: 100% real images (D-Fire)\n","- üü† `synthetic`: 100% synthetic images (Yunnan UE5)\n","- üü£ `mixed`: 50% synthetic, 50% real\n","\n","We also define model filenames dynamically and ensure reproducibility with a fixed random seed. The total number of training samples is kept constant for the mixed dataset (5,260), and filenames are structured to reflect the data composition used during training.\n"],"metadata":{"id":"Ylo-h99xWD05"}},{"cell_type":"code","source":["import os\n","import random\n","import torch\n","import numpy as np\n","\n","# üîß Adjustable configuration\n","syn_ratio = 0.50                     # Used only for the mixed dataset\n","total_samples = 5260                # Fixed total sample size for mixed dataset\n","\n","# üóÇÔ∏è Paths to training data\n","real_image_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/images\"\n","real_label_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/labels\"\n","\n","syn_image_dir  = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/yunnan/synthetic_all/images\"\n","syn_label_dir  = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/yunnan/synthetic_all/labels\"\n","\n","# üß† Model filenames based on dataset type\n","model_paths = {\n","    \"real\":    \"resnet_real_100_ft.pt\",\n","    \"synthetic\": \"resnet_synthetic_100_ft.pt\",\n","    \"mixed\":   f\"resnet_mixed_{int(syn_ratio*100)}syn_{int((1-syn_ratio)*100)}real_ft.pt\"\n","}\n","\n","# ‚úÖ Set random seed for reproducibility\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n"],"metadata":{"id":"DN_Bsc3vPRzr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## üßº Step 2: Define Image Transformations\n","\n","We define the image transformation pipeline used across all datasets. Images are resized to 224√ó224, normalized to ImageNet statistics, and converted to PyTorch tensors.\n","\n","This ensures compatibility with the input format expected by ResNet-50, which was pretrained on ImageNet.\n"],"metadata":{"id":"BU-4MJwtcSa9"}},{"cell_type":"code","source":["from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n"],"metadata":{"id":"fXX6CpoAZLAl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## ‚öôÔ∏è Step 3: Load Dataset, Pretrained Model, and Configure Fine-Tuning\n","\n","Based on the selected training mode (`\"real\"`, `\"synthetic\"`, or `\"mixed\"`), we perform the following:\n","\n","1. Load the appropriate dataset class with the predefined transform:\n","   - `FireClassificationDataset` for real images (D-Fire)\n","   - `FireClassificationSyntheticDataset` for synthetic images (Yunnan UE5)\n","   - `FireClassificationMixedDataset` for a fixed-ratio combination of both\n","\n","2. Split the full dataset into training and validation subsets using an 80/20 split with a fixed random seed (`seed=42`) to ensure reproducibility.\n","\n","3. Load the corresponding Phase 1 model (`*_100.pt`), which was trained using feature extraction (frozen base, trained `fc` layer only).\n","\n","4. Construct the Adam optimizer using only the parameters marked with `requires_grad=True`. Fine-tuning will be handled automatically inside the `train_model()` helper by unfreezing `layer4` and `fc` when `fine_tune=True`.\n","\n","This setup ensures consistent dataset usage and training conditions across all modes, and enables us to isolate the impact of fine-tuning deeper convolutional layers on classification performance.\n"],"metadata":{"id":"DN8PurielUdY"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader, random_split\n","from torchvision import models\n","from torch import nn, optim\n","from utils.fire_classification_dataset import (\n","    FireClassificationDataset,\n","    FireClassificationSyntheticDataset,\n","    FireClassificationMixedDataset\n",")\n","\n","# üîò SELECT WHICH MODEL TO TRAIN\n","selected_mode = \"real\"  # Options: \"real\", \"synthetic\", \"mixed\"\n","print(f\"\\nüì¶ Selected mode: {selected_mode.upper()}\")\n","\n","# üñ•Ô∏è Set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","using_gpu = torch.cuda.is_available()\n","print(f\"üñ•Ô∏è Using device: {device} ({'GPU enabled' if using_gpu else 'CPU only'})\")\n","\n","# ‚úÖ Training parameters\n","batch_size = 32\n","num_epochs = 5\n","learning_rate = 1e-4\n","print(f\"üìå Training config ‚Üí Batch size: {batch_size}, Epochs: {num_epochs}, LR: {learning_rate}\")\n","\n","# ‚úÖ Load dataset based on selected mode\n","if selected_mode == \"real\":\n","    print(\"üîπ Loading 100% real dataset (D-Fire)...\")\n","    full_dataset = FireClassificationDataset(real_image_dir, real_label_dir, transform=transform)\n","    pretrained_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100.pt\"\n","\n","elif selected_mode == \"synthetic\":\n","    print(\"üî∏ Loading 100% synthetic dataset (Yunnan)...\")\n","    full_dataset = FireClassificationSyntheticDataset(syn_image_dir, syn_label_dir, transform=transform)\n","    pretrained_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_synthetic_100.pt\"\n","\n","elif selected_mode == \"mixed\":\n","    print(\"üü£ Loading 50/50 mixed dataset (Real + Synthetic)...\")\n","    print(f\"   ‚Üí Synthetic ratio: {syn_ratio}, Total samples: {total_samples}\")\n","    full_dataset = FireClassificationMixedDataset(\n","        real_image_dir, real_label_dir,\n","        syn_image_dir, syn_label_dir,\n","        syn_ratio=syn_ratio,\n","        total_samples=total_samples,\n","        transform=transform\n","    )\n","    pretrained_path = f\"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_mixed_{int(syn_ratio*100)}syn_{int((1-syn_ratio)*100)}real.pt\"\n","\n","else:\n","    raise ValueError(\"‚ùå Invalid mode. Choose from: 'real', 'synthetic', or 'mixed'.\")\n","\n","# ‚úÖ Split into train and validation subsets (80/20)\n","train_ratio = 0.8\n","train_size = int(train_ratio * len(full_dataset))\n","val_size = len(full_dataset) - train_size\n","generator = torch.Generator().manual_seed(42)\n","\n","train_data, val_data = random_split(full_dataset, [train_size, val_size], generator=generator)\n","train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","\n","print(f\"üìä Dataset split ‚Üí Train: {train_size}, Validation: {val_size}\")\n","\n","# ‚úÖ Load pretrained model from Phase 1 (CPU-safe)\n","print(f\"\\nüîß Loading pretrained Phase 1 model: {pretrained_path}\")\n","model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, 2)\n","model.load_state_dict(torch.load(pretrained_path, map_location=device))\n","model = model.to(device)\n","print(\"‚úÖ Model loaded and moved to device.\")\n","\n","# ‚úÖ Construct optimizer using only trainable parameters\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n","print(\"üõ†Ô∏è Optimizer configured (Adam, fine-tuning mode).\")\n","\n","# ‚úÖ Set save path for fine-tuned model\n","save_path = f\"/content/drive/MyDrive/fire-detection-dissertation/models/{model_paths[selected_mode]}\"\n","print(f\"üíæ Fine-tuned model will be saved to: {save_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pceHNfeakfCl","executionInfo":{"status":"ok","timestamp":1753474578380,"user_tz":-60,"elapsed":6432,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"2604e491-ec41-4fbe-f336-4370ba7041fc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üì¶ Selected mode: REAL\n","üñ•Ô∏è Using device: cpu (CPU only)\n","üìå Training config ‚Üí Batch size: 32, Epochs: 5, LR: 0.0001\n","üîπ Loading 100% real dataset (D-Fire)...\n","üìä Dataset split ‚Üí Train: 13777, Validation: 3445\n","\n","üîß Loading pretrained Phase 1 model: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100.pt\n","‚úÖ Model loaded and moved to device.\n","üõ†Ô∏è Optimizer configured (Adam, fine-tuning mode).\n","üíæ Fine-tuned model will be saved to: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100_ft.pt\n"]}]},{"cell_type":"markdown","source":["## üîÅ Step 4: Train the Fine-Tuned Model (layer4 + fc)\n","\n","In this step, we begin training the selected model using the `train_model()` helper function.\n","\n","- `fine_tune=True` ensures that both `layer4` and `fc` are unfrozen and trained.\n","- The model weights are initialized from the Phase 1 checkpoint (trained with feature extraction).\n","- The model will be trained for 5 additional epochs using the same dataset composition as in Phase 1.\n","- Results will be printed at the end of each epoch and the best-performing model (by F1 score) will be saved to the specified path.\n"],"metadata":{"id":"TLVcdlNOq8SY"}},{"cell_type":"code","source":["from utils.train_model import train_model\n","from torch.nn import CrossEntropyLoss\n","\n","# ‚úÖ Define loss function\n","criterion = CrossEntropyLoss()\n","\n","# ‚úÖ Start training (with fine-tuning)\n","train_losses, val_losses = train_model(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=num_epochs,\n","    device=device,\n","    save_path=save_path,\n","    fine_tune=True,  #  Fine-tune layer4 + fc\n","    print_every=1,\n","    print_batch_loss=False\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nBIaToEXoNgV","outputId":"0fdf15f5-5bdd-44b7-f124-867073b02848","executionInfo":{"status":"ok","timestamp":1753509992545,"user_tz":-60,"elapsed":21864650,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}}},"execution_count":6,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","üîç Model device: cpu\n","üîß Fine-tuning mode: Unfreezing layer4 and fc...\n","üìä Trainable parameters: 14968834\n","\n","üîÅ Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [1/5] | Train Loss: 0.1364 | Val Loss: 0.0884 | Acc: 0.9710 | Precision: 0.9471 | Recall: 0.9451 | F1: 0.9461 | Time: 21044.6s\n","üíæ New best model saved (F1: 0.9461) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100_ft.pt\n","\n","üîÅ Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [2/5] | Train Loss: 0.0546 | Val Loss: 0.1140 | Acc: 0.9663 | Precision: 0.9161 | Recall: 0.9634 | F1: 0.9391 | Time: 3536.8s\n","\n","üîÅ Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [3/5] | Train Loss: 0.0279 | Val Loss: 0.1315 | Acc: 0.9669 | Precision: 0.9605 | Recall: 0.9150 | F1: 0.9372 | Time: 3527.7s\n","\n","üîÅ Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [4/5] | Train Loss: 0.0226 | Val Loss: 0.1044 | Acc: 0.9724 | Precision: 0.9523 | Recall: 0.9451 | F1: 0.9487 | Time: 3575.8s\n","üíæ New best model saved (F1: 0.9487) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_real_100_ft.pt\n","\n","üîÅ Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["                                                                "]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [5/5] | Train Loss: 0.0198 | Val Loss: 0.1169 | Acc: 0.9713 | Precision: 0.9621 | Recall: 0.9300 | F1: 0.9458 | Time: 3717.3s\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}]},{"cell_type":"code","source":["# ‚úÖ 1. Navigate to the Git-tracked repo folder\n","%cd /content/fire-detection-dissertation\n","\n","# ‚úÖ 2. Move the notebook from Drive into the repo so Git can track it\n","!mv /content/drive/MyDrive/fire-detection-dissertation/notebooks/06_train_resnet_finetuned.ipynb /content/fire-detection-dissertation/notebooks/\n","\n","# Optional: confirm it's now inside the repo\n","!ls notebooks/\n","\n","# ‚úÖ 3. Stage the notebook for commit\n","!git add notebooks/06_train_resnet_finetuned.ipynb\n","\n","# ‚úÖ 4. Commit with a message\n","!git commit -m \"Added Phase 2 fine-tuning notebook with modular support for real/synthetic/mixed models\n","\"\n","\n","# ‚úÖ 5. Push to GitHub\n","!git push\n"],"metadata":{"id":"BU7ALzPB5JXM"},"execution_count":null,"outputs":[]}]}