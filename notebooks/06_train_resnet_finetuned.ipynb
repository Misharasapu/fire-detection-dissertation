{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyOGmBLaBawMQ0ikupcFDavm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Fine-Tuning ResNet-50 on Real, Synthetic, and Mixed Fire Datasets\n",
    "\n",
    "This notebook fine-tunes ResNet-50 classification models using three dataset compositions:\n",
    "- **100% real** images from the D-Fire dataset.  \n",
    "- **100% synthetic** images from the Yunnan dataset (Unreal Engine–generated).  \n",
    "- **50/50 mixed** composition using the `FireClassificationMixedDataset` class.  \n",
    "\n",
    "The objective is to assess whether fine-tuning improves performance relative to feature extraction, particularly when the amount of real data is limited. Fine-tuning is performed by unfreezing the final ResNet-50 block (`layer4`) and the fully connected layer (`fc`), while keeping earlier layers frozen.\n",
    "\n",
    "Each model is trained for five epochs using the reusable `train_model` function from `utils/train_model.py`, with validation on the held-out D-Fire validation set. The results are compared directly against their frozen (Phase 1) counterparts.\n"
   ],
   "metadata": {
    "id": "s1pQkO-uOy1J"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook Setup: Mount Drive and Clone GitHub Repository\n",
    "\n",
    "This cell prepares the Colab environment so the notebook can be reproduced in any new session:\n",
    "\n",
    "- Mount Google Drive to access datasets, secrets, and checkpoints.  \n",
    "- Load the GitHub personal access token from Drive.  \n",
    "- Clone the `fire-detection-dissertation` repository.  \n",
    "- Navigate into the cloned repository directory.  \n",
    "- Configure the Git author identity for commits within the session.  \n",
    "\n",
    "**Note:** This cell must be executed at the start of every new Colab session.\n"
   ],
   "metadata": {
    "id": "S9eIgnXxOye4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v8Wb3b_UN773"
   },
   "outputs": [],
   "source": [
    "# Notebook setup: mount Google Drive and clone the GitHub repository\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "if not os.path.ismount(\"/content/drive\"):\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "# 2. Load the GitHub personal access token from Drive\n",
    "token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n",
    "with open(token_path, \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "# 3. Clone the GitHub repository (force a fresh copy each session)\n",
    "username = \"Misharasapu\"\n",
    "repo = \"fire-detection-dissertation\"\n",
    "clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n",
    "repo_path = f\"/content/{repo}\"\n",
    "\n",
    "# Remove any existing clone to avoid conflicts\n",
    "!rm -rf {repo_path}\n",
    "\n",
    "# Clone the repository and move into the directory\n",
    "%cd /content\n",
    "!git clone {clone_url}\n",
    "%cd {repo}\n",
    "\n",
    "# 4. Configure Git author identity (required in Colab sessions)\n",
    "!git config --global user.name \"Misharasapu\"\n",
    "!git config --global user.email \"misharasapu@gmail.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define Dataset Type, Paths, and Model Filenames\n",
    "\n",
    "In this step, the training configuration is defined for each model to be fine-tuned. Three dataset types are used:\n",
    "\n",
    "- `real`: 100% real images (D-Fire).  \n",
    "- `synthetic`: 100% synthetic images (Yunnan, UE5-generated).  \n",
    "- `mixed`: 50% real and 50% synthetic images.  \n",
    "\n",
    "Model filenames are generated dynamically to reflect the dataset composition. For the mixed dataset, the total number of training samples is fixed at 5,260 to ensure comparability across runs. A fixed random seed is also set for reproducibility.\n"
   ],
   "metadata": {
    "id": "Ylo-h99xWD05"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Adjustable configuration\n",
    "syn_ratio = 0.50          # Used only for the mixed dataset\n",
    "total_samples = 5260      # Fixed total sample size for mixed dataset\n",
    "\n",
    "# Paths to training data\n",
    "real_image_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/images\"\n",
    "real_label_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/D-Fire/train/labels\"\n",
    "\n",
    "# Yunnan synthetic data\n",
    "syn_image_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/yunnan/synthetic_all/images\"\n",
    "syn_label_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/yunnan/synthetic_all/labels\"\n",
    "\n",
    "# Model filenames based on dataset type (aligned with Phase 2 naming convention)\n",
    "model_paths = {\n",
    "    \"real\": \"resnet_outdoor_real_100_ft_phase2.pt\",\n",
    "    \"synthetic\": \"resnet_outdoor_synthetic_100_ft_phase2.pt\",\n",
    "    \"mixed\": f\"resnet_outdoor_{int(syn_ratio * 100)}syn_{int((1 - syn_ratio) * 100)}real_ft_phase2.pt\",\n",
    "}\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n"
   ],
   "metadata": {
    "id": "DN_Bsc3vPRzr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define Image Transformations\n",
    "\n",
    "The image transformation pipeline resizes images to 224×224 and converts them to PyTorch tensors, with pixel values scaled to the [0,1] range.  \n",
    "\n",
    "No additional normalization is applied, ensuring consistency with the final preprocessing policy adopted across all experiments. This format is compatible with ResNet-50 input requirements.\n"
   ],
   "metadata": {
    "id": "BU-4MJwtcSa9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2 – Image transformations (applied to both training and validation datasets)\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()  # scale pixel values to [0,1]\n",
    "])\n",
    "\n",
    "print(\"Image transforms set: Resize(224,224) → ToTensor() (no normalization applied)\")\n"
   ],
   "metadata": {
    "id": "fXX6CpoAZLAl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755626168704,
     "user_tz": -60,
     "elapsed": 7106,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4c747a91-002e-4813-ab77-b8299d1e1fef"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transforms set: Resize(224,224) → ToTensor()  [no normalization]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Load Dataset, Pretrained Model, and Configure Fine-Tuning\n",
    "\n",
    "Based on the selected training mode (`\"real\"`, `\"synthetic\"`, or `\"mixed\"`), this step:\n",
    "\n",
    "1. Loads the appropriate dataset with the predefined transform:  \n",
    "   - `FireClassificationDataset` for real images (D-Fire).  \n",
    "   - `FireClassificationDataset` with `dataset_type=\"synthetic\"` for Yunnan (UE5).  \n",
    "   - `FireClassificationMixedDataset` for a fixed-ratio combination of real and synthetic images.\n",
    "\n",
    "2. Splits the full dataset into training and validation subsets using an 80/20 split with a fixed random seed (`seed=42`) for reproducibility.\n",
    "\n",
    "3. Loads the corresponding Phase-1 checkpoint (feature extraction; frozen backbone, trained `fc`) using the final naming convention (e.g., `resnet_outdoor_real_100_phase1.pt`).\n",
    "\n",
    "4. Configures fine-tuning by unfreezing `layer4` and `fc` (all earlier layers remain frozen). The optimizer is constructed over parameters with `requires_grad=True` only.\n",
    "\n",
    "This setup keeps dataset usage and training conditions consistent across modes and isolates the impact of fine-tuning deeper layers on classification performance.\n"
   ],
   "metadata": {
    "id": "DN8PurielUdY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from utils.fire_classification_dataset import (\n",
    "    FireClassificationDataset,\n",
    "    FireClassificationMixedDataset\n",
    ")\n",
    "\n",
    "# Select which model to train\n",
    "selected_mode = \"real\"  # Options: \"real\", \"synthetic\", \"mixed\"\n",
    "print(f\"\\nSelected mode: {selected_mode.upper()}\")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "using_gpu = torch.cuda.is_available()\n",
    "print(f\"Using device: {device} ({'GPU enabled' if using_gpu else 'CPU only'})\")\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 1e-4\n",
    "print(f\"Training config → Batch size: {batch_size}, Epochs: {num_epochs}, LR: {learning_rate}\")\n",
    "\n",
    "# Build dataset by mode\n",
    "if selected_mode == \"real\":\n",
    "    print(\"Loading 100% real dataset (D-Fire)...\")\n",
    "    full_dataset = FireClassificationDataset(\n",
    "        image_dir=real_image_dir,\n",
    "        label_dir=real_label_dir,\n",
    "        transform=transform,\n",
    "        dataset_type=\"real\"\n",
    "    )\n",
    "    pretrained_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_phase1.pt\"\n",
    "\n",
    "elif selected_mode == \"synthetic\":\n",
    "    print(\"Loading 100% synthetic dataset (Yunnan)...\")\n",
    "    full_dataset = FireClassificationDataset(\n",
    "        image_dir=syn_image_dir,\n",
    "        label_dir=syn_label_dir,\n",
    "        transform=transform,\n",
    "        dataset_type=\"synthetic\"\n",
    "    )\n",
    "    pretrained_path = \"/content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_synthetic_100_phase1.pt\"\n",
    "\n",
    "elif selected_mode == \"mixed\":\n",
    "    print(\"Loading mixed dataset (Real + Synthetic)...\")\n",
    "    print(f\"   → Synthetic ratio: {syn_ratio:.2f}, Total samples: {total_samples}\")\n",
    "    full_dataset = FireClassificationMixedDataset(\n",
    "        real_image_dir=real_image_dir,\n",
    "        real_label_dir=real_label_dir,\n",
    "        syn_image_dir=syn_image_dir,\n",
    "        syn_label_dir=syn_label_dir,\n",
    "        syn_ratio=syn_ratio,\n",
    "        total_samples=total_samples,\n",
    "        transform=transform\n",
    "    )\n",
    "    pretrained_path = (\n",
    "        f\"/content/drive/MyDrive/fire-detection-dissertation/models/\"\n",
    "        f\"resnet_outdoor_{int(syn_ratio*100)}syn_{int((1-syn_ratio)*100)}real_phase1.pt\"\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"Invalid mode. Choose from: 'real', 'synthetic', or 'mixed'.\")\n",
    "\n",
    "# Split into train / val\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_data, val_data = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "print(f\"Dataset split → Train: {train_size}, Validation: {val_size}\")\n",
    "\n",
    "# Load Phase-1 checkpoint safely\n",
    "print(f\"\\nLoading pretrained Phase 1 model: {pretrained_path}\")\n",
    "if not os.path.exists(pretrained_path):\n",
    "    raise FileNotFoundError(f\"Checkpoint not found at: {pretrained_path}\")\n",
    "\n",
    "# Note: keeping parity with earlier runs that use pretrained ImageNet weights\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "state = torch.load(pretrained_path, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model = model.to(device)\n",
    "print(\"Model loaded and moved to device.\")\n",
    "\n",
    "# Fine-tuning policy (Phase 2): unfreeze only layer4 + fc\n",
    "print(\"\\nFine-tuning setup → freeze all, then unfreeze layer4 + fc\")\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "for p in model.layer4.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# Quick summary of trainable parameters\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable params: {trainable_params:,} / {total_params:,} \"\n",
    "      f\"({100.0 * trainable_params / total_params:.2f}% of model)\")\n",
    "\n",
    "# Optimizer on trainable params only\n",
    "optimizer = optim.Adam((p for p in model.parameters() if p.requires_grad), lr=learning_rate)\n",
    "print(\"Optimizer configured (Adam) on layer4 + fc only — fine-tuning mode active.\")\n",
    "\n",
    "# Save path for the fine-tuned model\n",
    "save_path = f\"/content/drive/MyDrive/fire-detection-dissertation/models/{model_paths[selected_mode]}\"\n",
    "print(f\"Fine-tuned model will be saved to: {save_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pceHNfeakfCl",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755626339828,
     "user_tz": -60,
     "elapsed": 987,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "7333f2a4-4e14-4bb0-82fc-6580f4f670ff"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "📦 Selected mode: REAL\n",
      "🖥️ Using device: cpu (CPU only)\n",
      "📌 Training config → Batch size: 32, Epochs: 5, LR: 0.0001\n",
      "🔹 Loading 100% real dataset (D-Fire)...\n",
      "📊 Dataset split → Train: 13777, Validation: 3445\n",
      "\n",
      "🔧 Loading pretrained Phase 1 model: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_phase1.pt\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Model loaded and moved to device.\n",
      "\n",
      "🧩 Fine‑tuning setup → Freeze all, then unfreeze layer4 + fc\n",
      "🔎 Trainable params: 14,968,834 / 23,512,130 (63.66% of model)\n",
      "🛠️ Optimizer configured (Adam) on layer4 + fc only — fine‑tuning mode active.\n",
      "💾 Fine‑tuned model will be saved to: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_ft_phase2.pt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Train the Fine-Tuned Model (layer4 + fc)\n",
    "\n",
    "This step starts training using the `train_model()` helper. Fine-tuning has already been configured by unfreezing `layer4` and `fc` in the model setup, and the optimizer was constructed over the parameters with `requires_grad=True`. The weights were initialised from the Phase-1 checkpoint (feature extraction).\n",
    "\n",
    "Training runs for five epochs on the same dataset composition used in Phase 1, and the best checkpoint is saved to the configured path.\n"
   ],
   "metadata": {
    "id": "TLVcdlNOq8SY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.train_model import train_model\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# Define loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Start training (fine-tuning is already configured by unfreezing layer4 + fc)\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    save_path=save_path,\n",
    "    print_every=1,\n",
    "    print_batch_loss=False\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBIaToEXoNgV",
    "outputId": "0854b111-b31c-43d1-d338-25ebde9ae4a5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755661547168,
     "user_tz": -60,
     "elapsed": 6032473,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Model device: cpu\n",
      "📊 Trainable parameters: 14968834\n",
      "\n",
      "🔁 Epoch 1/5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ""
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [1/5] | Train Loss: 0.1366 | Val Loss: 0.0937 | Acc: 0.9689 | Precision: 0.9497 | Recall: 0.9343 | F1: 0.9419 | Time: 16591.3s\n",
      "💾 New best model saved (F1: 0.9419) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_ft_phase2.pt\n",
      "\n",
      "🔁 Epoch 2/5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ""
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [2/5] | Train Loss: 0.0499 | Val Loss: 0.1230 | Acc: 0.9608 | Precision: 0.9553 | Recall: 0.8967 | F1: 0.9250 | Time: 4633.5s\n",
      "\n",
      "🔁 Epoch 3/5\n"
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ""
     ]
    },
    {
     "metadata": {
      "tags": null
     },
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Epoch [3/5] | Train Loss: 0.0321 | Val Loss: 0.1272 | Acc: 0.9704 | Precision: 0.9366 | Recall: 0.9548 | F1: 0.9456 | Time: 4691.5s\n",
      "💾 New best model saved (F1: 0.9456) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_ft_phase2.pt\n",
      "\n",
      "🔁 Epoch 4/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [4/5] | Train Loss: 0.0221 | Val Loss: 0.1066 | Acc: 0.9724 | Precision: 0.9484 | Recall: 0.9494 | F1: 0.9489 | Time: 4680.4s\n",
      "💾 New best model saved (F1: 0.9489) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_ft_phase2.pt\n",
      "\n",
      "🔁 Epoch 5/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [5/5] | Train Loss: 0.0145 | Val Loss: 0.1251 | Acc: 0.9733 | Precision: 0.9614 | Recall: 0.9386 | F1: 0.9499 | Time: 4607.4s\n",
      "💾 New best model saved (F1: 0.9499) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_outdoor_real_100_ft_phase2.pt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ✅ 1. Navigate to the Git-tracked repo folder\n",
    "%cd /content/fire-detection-dissertation\n",
    "\n",
    "# ✅ 2. Move the notebook from Drive into the repo so Git can track it\n",
    "!cp /content/drive/MyDrive/fire-detection-dissertation/notebooks/06_train_resnet_finetuned.ipynb /content/fire-detection-dissertation/notebooks/\n",
    "\n",
    "# Optional: confirm it's now inside the repo\n",
    "!ls notebooks/\n",
    "\n",
    "# ✅ 3. Stage the notebook for commit\n",
    "!git add notebooks/06_train_resnet_finetuned.ipynb\n",
    "\n",
    "# ✅ 4. Commit with a message\n",
    "!git commit -m \"Refactored Phase 2 fine-tuning notebook with unnormalised pipeline and updated dataset handling\"\n",
    "\n",
    "# ✅ 5. Push to GitHub\n",
    "!git push\n"
   ],
   "metadata": {
    "id": "1JQID-HWZhTu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755684306783,
     "user_tz": -60,
     "elapsed": 542,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "ccfce2b2-3a66-4e70-c8b2-b60187f8a9f0"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Errno 2] No such file or directory: '/content/fire-detection-dissertation'\n",
      "/content\n",
      "cp: cannot stat '/content/drive/MyDrive/fire-detection-dissertation/notebooks/06_train_resnet_finetuned.ipynb': No such file or directory\n",
      "ls: cannot access 'notebooks/': No such file or directory\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "fatal: not a git repository (or any of the parent directories): .git\n",
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0B9JW5Jk8Hvy"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
