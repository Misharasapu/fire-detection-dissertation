{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPTqNEaWgW5zNz4OL7tTc9i"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training Indoor ResNet-50 Models on Real and Mixed Fire Datasets\n",
    "\n",
    "This notebook trains ResNet-50 classification models for **indoor fire detection** using two dataset compositions:\n",
    "\n",
    "- **100% real** images from the PLOS ONE indoor dataset.  \n",
    "- **50/50 mixed** composition combining PLOS ONE real images with SYN-FIRE synthetic positives.  \n",
    "\n",
    "The objective is to evaluate best-case indoor performance for deployment scenarios (e.g., factories, warehouses, enclosed environments) and to assess whether supplementing limited real data with synthetic positives improves classification outcomes.\n",
    "\n",
    "Training is conducted in **frozen feature extraction mode** for comparability with Phase 1 results. Models are validated on the held-out PLOS ONE validation set, and final performance is measured on the PLOS ONE test set. Results are compared against outdoor-trained models from Phases 1–3 to highlight the impact of indoor-focused training.\n"
   ],
   "metadata": {
    "id": "91A6RgYEIyMg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook Setup: Mount Drive and Clone GitHub Repository\n",
    "\n",
    "This cell prepares the Colab environment so the notebook can be reproduced in any new session:\n",
    "\n",
    "- Mount Google Drive to access datasets, secrets, and checkpoints.  \n",
    "- Load the GitHub personal access token from Drive.  \n",
    "- Clone the `fire-detection-dissertation` repository.  \n",
    "- Navigate into the cloned repository directory.  \n",
    "- Configure the Git author identity for commits within the session.  \n",
    "\n",
    "**Note:** This cell must be executed at the start of every new Colab session.\n"
   ],
   "metadata": {
    "id": "Lzezs53_Iyth"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RO7-6C5iICXG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755613918691,
     "user_tz": -60,
     "elapsed": 1503,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "2176ce59-c170-4fa4-9d93-399d9c803815"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "Cloning into 'fire-detection-dissertation'...\n",
      "remote: Enumerating objects: 140, done.\u001B[K\n",
      "remote: Counting objects: 100% (140/140), done.\u001B[K\n",
      "remote: Compressing objects: 100% (103/103), done.\u001B[K\n",
      "remote: Total 140 (delta 69), reused 102 (delta 35), pack-reused 0 (from 0)\u001B[K\n",
      "Receiving objects: 100% (140/140), 4.33 MiB | 32.38 MiB/s, done.\n",
      "Resolving deltas: 100% (69/69), done.\n",
      "/content/fire-detection-dissertation\n"
     ]
    }
   ],
   "source": [
    "# Notebook setup: mount Google Drive and clone the GitHub repository\n",
    "\n",
    "# 1. Mount Google Drive\n",
    "import os\n",
    "from google.colab import drive\n",
    "if not os.path.ismount(\"/content/drive\"):\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "# 2. Load the GitHub personal access token from Drive\n",
    "token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n",
    "with open(token_path, \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "# 3. Clone the GitHub repository (force a fresh copy each session)\n",
    "username = \"Misharasapu\"\n",
    "repo = \"fire-detection-dissertation\"\n",
    "clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n",
    "repo_path = f\"/content/{repo}\"\n",
    "\n",
    "# Remove any existing clone to avoid conflicts\n",
    "!rm -rf {repo_path}\n",
    "\n",
    "# Clone the repository and move into the directory\n",
    "%cd /content\n",
    "!git clone {clone_url}\n",
    "%cd {repo}\n",
    "\n",
    "# 4. Configure Git author identity (required in Colab sessions)\n",
    "!git config --global user.name \"Misharasapu\"\n",
    "!git config --global user.email \"misharasapu@gmail.com\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 1: Define Dataset Type, Paths, and Model Filenames\n",
    "\n",
    "In this step, the Phase 4 indoor training configuration is defined. Only one model is trained at a time, controlled by the `selected_model` variable:\n",
    "\n",
    "- **indoor_real**: 100% real images from the PLOS ONE dataset (indoor).  \n",
    "- **indoor_mixed**: 50% PLOS ONE real + 50% SYN-FIRE synthetic positives.  \n",
    "\n",
    "> **Note:** The SYN-FIRE dataset contains only positive (fire) images, stored in  \n",
    "> `/synthetic/syn-fire/synthetic_all/images` and `/synthetic/syn-fire/synthetic_all/masks`.  \n",
    "> It is used exclusively for training augmentation. Validation and test sets remain PLOS ONE only.\n",
    "\n",
    "Model filenames follow the unified convention (`resnet_<domain>_<composition>_phase4.pt`). A fixed random seed is set for reproducibility.  \n",
    "An optional `total_samples` cap can be applied to mirror Phase 1 fairness (e.g., 5,260 samples). Leaving it as `None` will use the full PLOS ONE training split.\n"
   ],
   "metadata": {
    "id": "OSjvR0qvNGPW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 1: Dataset types, paths, and filenames (Phase 4: Indoor)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Paths to training/validation/test data (PLOS ONE, indoor focus)\n",
    "plos_train_img_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/train/images\"\n",
    "plos_train_lbl_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/train/labels\"\n",
    "plos_val_img_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/valid/images\"\n",
    "plos_val_lbl_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/valid/labels\"\n",
    "plos_test_img_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/test/images\"\n",
    "plos_test_lbl_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/test/labels\"\n",
    "\n",
    "# SYN-FIRE (indoor synthetic positives only, used for mixed model)\n",
    "synfire_img_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/syn-fire/synthetic_all/images\"\n",
    "synfire_mask_dir = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/syn-fire/synthetic_all/masks\"\n",
    "\n",
    "# Model filenames (consistent with naming convention)\n",
    "model_paths = {\n",
    "    \"indoor_real\": \"resnet_indoor_real_100_phase4.pt\",\n",
    "    \"indoor_mixed\": \"resnet_indoor_50syn_50real_phase4.pt\",\n",
    "}\n",
    "\n",
    "# Select which model to train for this run\n",
    "# Options: \"indoor_real\" or \"indoor_mixed\"\n",
    "selected_model = \"indoor_mixed\"\n",
    "\n",
    "# Reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "print(f\"Phase 4 setup complete. Selected model: {selected_model}\")\n",
    "print(\"Checkpoint will be saved as:\", model_paths[selected_model])\n",
    "print(\"PLOS train path:\", plos_train_img_dir)\n",
    "if selected_model == \"indoor_mixed\":\n",
    "    print(\"SYN-FIRE positives path:\", synfire_img_dir)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeXHJIqHI2nS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620152026,
     "user_tz": -60,
     "elapsed": 5,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "ef70a20b-6023-4df0-d7f3-474fbbbc8860"
   },
   "execution_count": 36,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Phase 4 setup complete. Selected model: indoor_mixed\n",
      "Checkpoint will be saved as: resnet_indoor_50syn_50real_phase4.pt\n",
      "PLOS train path: /content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/train/images\n",
      "SYN-FIRE positives path: /content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/syn-fire/synthetic_all/images\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Define Image Transformations\n",
    "\n",
    "The preprocessing pipeline used for both training and validation performs the following steps:  \n",
    "- Resize all images to 224×224.  \n",
    "- Convert images to PyTorch tensors.  \n",
    "\n",
    "No normalization is applied. All models from Phase 1 to Phase 4 are trained and evaluated on unnormalised images for consistency. This ensures alignment across training, validation, and testing, and also makes visual inspection of images more straightforward.  \n",
    "\n",
    "No data augmentation is applied. The test set is handled separately in the evaluation notebook.\n"
   ],
   "metadata": {
    "id": "HxgNxktEQa9b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 2: Image transformations (train and validation only; no augmentation, no normalization)\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()  # pixel values scaled to [0,1]\n",
    "])\n",
    "\n",
    "print(\"Image transforms set: Resize(224,224) → ToTensor() (no normalization applied)\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LF9jS53DN9mY",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620158502,
     "user_tz": -60,
     "elapsed": 5,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "72b2caa3-945a-4aeb-a0b7-7eaa0e6d355b"
   },
   "execution_count": 37,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transforms set: Resize(224,224) → ToTensor()  [no normalization]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Load Dataset and Build DataLoaders\n",
    "\n",
    "The dataset helper functions are imported from the repository, and the **PLOS ONE (indoor)** splits are loaded. Only the training and validation sets are used in this notebook. The test split is reserved for the evaluation notebook.\n",
    "\n",
    "- **Helper:** `FireClassificationDataset` with `dataset_type=\"plos\"` (maps class 0 → fire).  \n",
    "- **Splits:** use the existing `train/` and `valid/` directories.  \n",
    "- **Configuration:** one model per run. If `selected_model=\"indoor_real\"`, only PLOS ONE samples are used. Switching to `\"indoor_mixed\"` applies the `FireClassificationPhase4MixedFixed` loader (2000 PLOS real + 2000 SYN-FIRE positives) while keeping validation PLOS-only.\n"
   ],
   "metadata": {
    "id": "TZ3Mimz-SOKu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 3: Load dataset and build DataLoaders (train + validation only)\n",
    "\n",
    "import importlib\n",
    "import utils.fire_classification_dataset as fcd\n",
    "importlib.reload(fcd)  # ensure the notebook uses the latest version\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if selected_model == \"indoor_real\":\n",
    "    # PLOS-only (train + validation)\n",
    "    train_dataset = fcd.FireClassificationDataset(\n",
    "        image_dir=plos_train_img_dir,\n",
    "        label_dir=plos_train_lbl_dir,\n",
    "        transform=transform,\n",
    "        dataset_type=\"plos\",\n",
    "    )\n",
    "else:  # indoor_mixed\n",
    "    # Fixed 50/50 split: 2000 PLOS real + 2000 SYN-FIRE positives\n",
    "    train_dataset = fcd.FireClassificationPhase4MixedFixed(\n",
    "        real_image_dir=plos_train_img_dir,\n",
    "        real_label_dir=plos_train_lbl_dir,\n",
    "        syn_image_dir=synfire_img_dir,\n",
    "        syn_mask_dir=synfire_mask_dir,\n",
    "        n_real=2000,\n",
    "        n_syn=2000,\n",
    "        transform=transform,\n",
    "        seed=42,\n",
    "    )\n",
    "\n",
    "# Validation dataset (always PLOS-only)\n",
    "val_dataset = fcd.FireClassificationDataset(\n",
    "    image_dir=plos_val_img_dir,\n",
    "    label_dir=plos_val_lbl_dir,\n",
    "    transform=transform,\n",
    "    dataset_type=\"plos\",\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Selected model: {selected_model}\")\n",
    "print(f\"Training samples: {len(train_dataset)} | Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Batch size: {batch_size}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3EP0h3SQgCh",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620163525,
     "user_tz": -60,
     "elapsed": 109,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "8ea02e05-525a-469c-fb7b-882cae6fa59a"
   },
   "execution_count": 38,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Selected model: indoor_mixed\n",
      "Train samples: 4000 | Valid samples: 500\n",
      "Batch size: 32\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Debug: confirm composition of the indoor mixed dataset\n",
    "if selected_model == \"indoor_mixed\":\n",
    "    # Count samples\n",
    "    n_total = len(train_dataset)\n",
    "    n_real = len(train_dataset.real_indices)\n",
    "    n_syn = len(train_dataset.syn_indices)\n",
    "\n",
    "    print(f\"Indoor mixed dataset composition → Real: {n_real}, Synthetic: {n_syn}, Total: {n_total}\")\n",
    "\n",
    "    # Quick label distribution sanity check (first 200 samples only for speed)\n",
    "    labels = [int(train_dataset[i][1]) for i in range(200)]\n",
    "    n_fire = sum(labels)\n",
    "    n_no_fire = 200 - n_fire\n",
    "    print(f\"Label distribution (first 200 samples): Fire={n_fire}, No Fire={n_no_fire}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jCwAJXj1wmw2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620190744,
     "user_tz": -60,
     "elapsed": 23408,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "71cab6a8-c79a-4b41-ca44-249fc117f925"
   },
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "📊 Indoor mixed dataset composition → Real: 2000, Synthetic: 2000, Total: 4000\n",
      "✅ Sample label distribution (first 200): Fire=152, No Fire=48\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Build ResNet-50 (Feature Extraction), Define Loss and Optimizer\n",
    "\n",
    "This step follows the Phase-1 setup: load a pretrained ResNet-50, freeze the backbone, replace the final `fc` layer with a two-class head, and train only that head. The loss function is `CrossEntropyLoss` (two logits), and the optimizer is Adam over the head parameters. The checkpoint filename is derived from `model_paths[selected_model]`.\n"
   ],
   "metadata": {
    "id": "hdFUr1QHXaxM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 4: Model (feature extraction), loss, optimizer\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1) Pretrained ResNet-50 backbone\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 2) Freeze all backbone layers (feature extraction mode)\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 3) Replace classification head with a 2-class layer\n",
    "in_features = model.fc.in_features  # typically 2048\n",
    "model.fc = nn.Linear(in_features, 2)\n",
    "\n",
    "# 4) Ensure the new head is trainable\n",
    "for p in model.fc.parameters():\n",
    "    p.requires_grad = True\n",
    "\n",
    "# 5) Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# 6) Loss and optimizer (train head only)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4)\n",
    "\n",
    "# 7) Checkpoint path\n",
    "models_dir = \"/content/drive/MyDrive/fire-detection-dissertation/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "checkpoint_path = os.path.join(models_dir, model_paths[selected_model])\n",
    "\n",
    "# 8) Sanity check\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Device: {device} | Trainable params: {trainable} / {total} (only fc)\")\n",
    "print(f\"Checkpoint will be saved to: {checkpoint_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MlK-oNKlSpyV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1755620223691,
     "user_tz": -60,
     "elapsed": 477,
     "user": {
      "displayName": "Mishara Sapukotanage",
      "userId": "02206396968881771481"
     }
    },
    "outputId": "d7b81b64-9ff7-497c-8b4b-a8a6c37da1b0"
   },
   "execution_count": 40,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda | Trainable params: 4098 / 23512130 (only fc)\n",
      "Checkpoint will be saved to: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Train the Model (Feature Extraction Baseline)\n",
    "\n",
    "Training is executed using the `train_model()` helper from `utils/train_model.py`, which:\n",
    "\n",
    "- Utilises GPU if available.  \n",
    "- Tracks training and validation loss each epoch.  \n",
    "- Saves a checkpoint **only when the validation F1 score improves** to  \n",
    "  `models/{model_paths[selected_model]}`.  \n",
    "\n",
    "Training runs for `num_epochs` (default: 5) for consistency with earlier notebooks.\n"
   ],
   "metadata": {
    "id": "viFqM59LZWPB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Step 5: Train using the repository helper\n",
    "\n",
    "from utils.train_model import train_model\n",
    "\n",
    "# Epochs (consistent with earlier phases)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    save_path=checkpoint_path,  # e.g., models/resnet_indoor_real_100_phase4.pt\n",
    "    print_every=1,              # print one summary per epoch\n",
    "    print_batch_loss=False      # set True only for debugging\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete.\")\n",
    "print(f\"Best model saved to: {checkpoint_path}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4sTWzfH7Yew6",
    "outputId": "b88298e3-1081-405b-fdc4-f2217ab23a36"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "🔍 Model device: cuda:0\n",
      "📌 Feature extraction mode: Notebook is responsible for freezing/unfreezing.\n",
      "📊 Trainable parameters: 4098\n",
      "\n",
      "🔁 Epoch 1/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [1/5] | Train Loss: 0.3785 | Val Loss: 0.4209 | Acc: 0.8700 | Precision: 0.8205 | Recall: 0.9931 | F1: 0.8986 | Time: 195.1s\n",
      "💾 New best model saved (F1: 0.8986) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n",
      "\n",
      "🔁 Epoch 2/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [2/5] | Train Loss: 0.2057 | Val Loss: 0.3021 | Acc: 0.9120 | Precision: 0.8994 | Recall: 0.9552 | F1: 0.9264 | Time: 195.0s\n",
      "💾 New best model saved (F1: 0.9264) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n",
      "\n",
      "🔁 Epoch 3/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [3/5] | Train Loss: 0.1528 | Val Loss: 0.2577 | Acc: 0.9160 | Precision: 0.8974 | Recall: 0.9655 | F1: 0.9302 | Time: 195.2s\n",
      "💾 New best model saved (F1: 0.9302) → /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n",
      "\n",
      "🔁 Epoch 4/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                              "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "✅ Epoch [4/5] | Train Loss: 0.1301 | Val Loss: 0.2266 | Acc: 0.9180 | Precision: 0.9278 | Recall: 0.9310 | F1: 0.9294 | Time: 195.9s\n",
      "\n",
      "🔁 Epoch 5/5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "🚂 Training:  90%|████████▉ | 112/125 [02:52<00:21,  1.67s/it]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# ✅ 1. Navigate to the Git-tracked repo folder\n",
    "%cd /content/fire-detection-dissertation\n",
    "\n",
    "# ✅ 2. Move the notebook from Drive into the repo so Git can track it\n",
    "!mv /content/drive/MyDrive/fire-detection-dissertation/notebooks/07_train_resnet_indoor_models.ipynb /content/fire-detection-dissertation/notebooks/\n",
    "\n",
    "# Optional: confirm it's now inside the repo\n",
    "!ls notebooks/\n",
    "\n",
    "# ✅ 3. Stage the notebook for commit\n",
    "!git add notebooks/07_train_resnet_indoor_models.ipynb\n",
    "\n",
    "# ✅ 4. Commit with a message\n",
    "!git commit -m \"Added Phase 4 indoor training notebook (PLOS ONE real + SYN-FIRE mixed, unnormalised pipeline)\"\n",
    "\n",
    "# ✅ 5. Push to GitHub\n",
    "!git push\n"
   ],
   "metadata": {
    "id": "2J-hUrYeaL2g"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
