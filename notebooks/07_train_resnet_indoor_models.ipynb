{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPTqNEaWgW5zNz4OL7tTc9i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# üè≠ Training Indoor ResNet-50 Models on Real and Mixed Fire Datasets\n","\n","This notebook trains ResNet-50 classification models for **indoor fire detection** using two dataset compositions:\n","- 100% real images from the PLOS ONE indoor dataset\n","- 50/50 mixed composition using the PLOS ONE real dataset combined with SYN-FIRE synthetic positives\n","\n","The goal is to evaluate best-case indoor performance for deployment scenarios (e.g., factories, enclosed environments) and to assess whether supplementing limited real data with synthetic positives improves classification.\n","\n","Training is performed using ResNet-50 in frozen feature extraction mode for comparability with Phase 1 results. Models are validated on the held-out PLOS ONE validation set, and final performance is measured on the PLOS ONE test set. Results will be compared directly to outdoor-trained models from Phases 1‚Äì3 to demonstrate the impact of indoor-focused training.\n"],"metadata":{"id":"91A6RgYEIyMg"}},{"cell_type":"markdown","source":["## üì¶ Notebook Setup: Mount Drive & Clone GitHub Repo\n","\n","This cell ensures the notebook is reproducible in any new Colab session by:\n","\n","- Mounting your Google Drive (to access datasets, secrets, and checkpoints)\n","- Loading your GitHub token from Drive\n","- Cloning the fire-detection-dissertation repository\n","- Navigating into the correct folder\n","- Setting Git identity for future commits\n","\n","‚ö†Ô∏è **Note:** This cell must be run every time you open this notebook in a new Colab session.\n"],"metadata":{"id":"Lzezs53_Iyth"}},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RO7-6C5iICXG","executionInfo":{"status":"ok","timestamp":1755613918691,"user_tz":-60,"elapsed":1503,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"2176ce59-c170-4fa4-9d93-399d9c803815"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'fire-detection-dissertation'...\n","remote: Enumerating objects: 140, done.\u001b[K\n","remote: Counting objects: 100% (140/140), done.\u001b[K\n","remote: Compressing objects: 100% (103/103), done.\u001b[K\n","remote: Total 140 (delta 69), reused 102 (delta 35), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (140/140), 4.33 MiB | 32.38 MiB/s, done.\n","Resolving deltas: 100% (69/69), done.\n","/content/fire-detection-dissertation\n"]}],"source":["# üîß Minimal Colab setup for any working notebook\n","\n","# 1. Mount Google Drive\n","import os\n","from google.colab import drive\n","if not os.path.ismount(\"/content/drive\"):\n","    drive.mount(\"/content/drive\")\n","\n","# 2. Load GitHub token securely from Drive\n","token_path = \"/content/drive/MyDrive/fire-detection-dissertation/secrets/github_token.txt\"\n","with open(token_path, \"r\") as f:\n","    token = f.read().strip()\n","\n","# 3. Clone the GitHub repo (force fresh clone for safety)\n","username = \"Misharasapu\"\n","repo = \"fire-detection-dissertation\"\n","clone_url = f\"https://{token}@github.com/{username}/{repo}.git\"\n","repo_path = f\"/content/{repo}\"\n","\n","# Optional: Remove old clone (safe to rerun)\n","!rm -rf {repo_path}\n","\n","# Clone fresh and move into the repo\n","%cd /content\n","!git clone {clone_url}\n","%cd {repo}\n","\n","# 4. Set Git identity (required in Colab sessions)\n","!git config --global user.name \"Misharasapu\"\n","!git config --global user.email \"misharasapu@gmail.com\"\n"]},{"cell_type":"markdown","source":["## üß© Step 1: Define Dataset Type, Paths, and Model Filenames\n","\n","In this step, we set up the **Phase 4 indoor training configuration**. Only **one model is trained at a time**, controlled by the `selected_model` variable:\n","\n","- üü¢ **indoor_real**: 100% real images from the **PLOS ONE** dataset (indoor)  \n","- üü† **indoor_mixed**: 50% PLOS ONE real + 50% SYN-FIRE synthetic positives  \n","  > **Note:** The SYN-FIRE dataset contains **only positive (fire) images**, stored under  \n","  `/synthetic/syn-fire/synthetic_all/images` and `/synthetic/syn-fire/synthetic_all/masks`.  \n","  It is used **only for training augmentation**. Validation and test remain **PLOS ONE only**.\n","\n","We also define model filenames using the unified naming convention (`resnet_<domain>_<composition>_phase4.pt`) and set a fixed random seed for reproducibility.  \n","An optional `total_samples` cap can be applied to mirror Phase 1 fairness (e.g., 5,260 samples). Leaving it as `None` will use the full PLOS ONE training split.\n"],"metadata":{"id":"OSjvR0qvNGPW"}},{"cell_type":"code","source":["# --- Step 1: Dataset types, paths, filenames (Phase 4: Indoor) ---\n","\n","import os\n","import random\n","import torch\n","import numpy as np\n","\n","\n","# ‚úÖ Paths to training/val/test data (Phase 4: indoor focus)\n","plos_train_img_dir  = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/train/images\"\n","plos_train_lbl_dir  = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/train/labels\"\n","plos_val_img_dir    = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/valid/images\"\n","plos_val_lbl_dir    = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/valid/labels\"\n","plos_test_img_dir   = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/test/images\"\n","plos_test_lbl_dir   = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/test/labels\"\n","\n","# SYN-FIRE (indoor synthetic positives only, used for mixed model)\n","synfire_img_dir     = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/syn-fire/synthetic_all/images\"\n","synfire_mask_dir    = \"/content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/syn-fire/synthetic_all/masks\"\n","\n","# ‚úÖ Model filenames (consistent with naming convention)\n","model_paths = {\n","    \"indoor_real\":   \"resnet_indoor_real_100_phase4.pt\",\n","    \"indoor_mixed\":  \"resnet_indoor_50syn_50real_phase4.pt\",\n","}\n","\n","# ‚úÖ Select which model to train for this run\n","# Options: \"indoor_real\" or \"indoor_mixed\"\n","selected_model = \"indoor_mixed\"\n","\n","# ‚úÖ Reproducibility\n","seed = 42\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","\n","print(f\"Phase 4 setup complete. Selected model: {selected_model}\")\n","print(\"Checkpoint will be saved as:\", model_paths[selected_model])\n","print(\"PLOS train path:\", plos_train_img_dir)\n","if selected_model == \"indoor_mixed\":\n","    print(\"SYN-FIRE positives path:\", synfire_img_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TeXHJIqHI2nS","executionInfo":{"status":"ok","timestamp":1755620152026,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"ef70a20b-6023-4df0-d7f3-474fbbbc8860"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Phase 4 setup complete. Selected model: indoor_mixed\n","Checkpoint will be saved as: resnet_indoor_50syn_50real_phase4.pt\n","PLOS train path: /content/drive/MyDrive/fire-detection-dissertation/data/raw/real/PLOS_ONE/train/images\n","SYN-FIRE positives path: /content/drive/MyDrive/fire-detection-dissertation/data/raw/synthetic/syn-fire/synthetic_all/images\n"]}]},{"cell_type":"markdown","source":["## üí† Step 2: Define Image Transformations\n","\n","We define the basic preprocessing pipeline used for both training and validation.  \n","Images are resized to 224√ó224 and converted to tensors.  \n","\n","üö´ No normalization is applied ‚Äî all models from Phase 1 to Phase 4 are now trained and evaluated on **unnormalised images** for consistency.  \n","This ensures that training, validation, and testing all use the same input format and allows easier visual inspection of images.  \n","\n","No data augmentation is applied.  \n","The test set will be handled separately in the evaluation notebook.\n"],"metadata":{"id":"HxgNxktEQa9b"}},{"cell_type":"code","source":["# --- Step 2: Image transforms (train + val only, no augmentation, no Normalize) ---\n","\n","from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),            # üëà no Normalize\n","])\n","\n","print(\"Transforms set: Resize(224,224) ‚Üí ToTensor()  [no normalization]\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LF9jS53DN9mY","executionInfo":{"status":"ok","timestamp":1755620158502,"user_tz":-60,"elapsed":5,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"72b2caa3-945a-4aeb-a0b7-7eaa0e6d355b"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["Transforms set: Resize(224,224) ‚Üí ToTensor()  [no normalization]\n"]}]},{"cell_type":"markdown","source":["## ‚öôÔ∏è Step 3: Load dataset and build DataLoaders\n","\n","We import the dataset helper from the repo and load the **PLOS ONE (indoor)** splits.  \n","Only train and valid are used in this notebook. Test is handled in the evaluation notebook.\n","\n","- Helper: `FireClassificationDataset` with `dataset_type=\"plos\"` so class 0 ‚Üí fire\n","- Splits: use the existing `train/` and `valid/` folders\n","- Modularity: one model per run. Currently `selected_model = \"indoor_real\"`. Switching later to `\"indoor_mixed\"` will change only the train loader.\n"],"metadata":{"id":"TZ3Mimz-SOKu"}},{"cell_type":"code","source":["# --- Step 3: Load dataset and build DataLoaders (train + valid only) ---\n","\n","import importlib\n","import utils.fire_classification_dataset as fcd\n","importlib.reload(fcd)  # üîÑ ensures notebook sees latest version\n","\n","from torch.utils.data import DataLoader\n","\n","\n","if selected_model == \"indoor_real\":\n","    # PLOS-only (train + valid)\n","    train_dataset = fcd.FireClassificationDataset(\n","        image_dir=plos_train_img_dir,\n","        label_dir=plos_train_lbl_dir,\n","        transform=transform,\n","        dataset_type=\"plos\",\n","    )\n","else:  # indoor_mixed\n","    # Fixed 50/50: 2000 PLOS real + 2000 SYN-FIRE (train only)\n","    train_dataset = fcd.FireClassificationPhase4MixedFixed(\n","        real_image_dir=plos_train_img_dir,\n","        real_label_dir=plos_train_lbl_dir,\n","        syn_image_dir=synfire_img_dir,\n","        syn_mask_dir=synfire_mask_dir,\n","        n_real=2000,\n","        n_syn=2000,\n","        transform=transform,\n","        seed=42,\n","    )\n","\n","# Validation stays PLOS-only\n","val_dataset = fcd.FireClassificationDataset(\n","    image_dir=plos_val_img_dir,\n","    label_dir=plos_val_lbl_dir,\n","    transform=transform,\n","    dataset_type=\"plos\",\n",")\n","\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n","val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","print(f\"Selected model: {selected_model}\")\n","print(f\"Train samples: {len(train_dataset)} | Valid samples: {len(val_dataset)}\")\n","print(f\"Batch size: {batch_size}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c3EP0h3SQgCh","executionInfo":{"status":"ok","timestamp":1755620163525,"user_tz":-60,"elapsed":109,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"8ea02e05-525a-469c-fb7b-882cae6fa59a"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected model: indoor_mixed\n","Train samples: 4000 | Valid samples: 500\n","Batch size: 32\n"]}]},{"cell_type":"code","source":["# --- Debug: Confirm composition of mixed dataset ---\n","if selected_model == \"indoor_mixed\":\n","    # Count samples\n","    n_total = len(train_dataset)\n","    n_real  = len(train_dataset.real_indices)\n","    n_syn   = len(train_dataset.syn_indices)\n","\n","    print(f\"üìä Indoor mixed dataset composition ‚Üí Real: {n_real}, Synthetic: {n_syn}, Total: {n_total}\")\n","\n","    # Sanity check: label distribution\n","    labels = [int(train_dataset[i][1]) for i in range(200)]  # sample first 200 for speed\n","    print(f\"‚úÖ Sample label distribution (first 200): Fire={sum(labels)}, No Fire={200 - sum(labels)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jCwAJXj1wmw2","executionInfo":{"status":"ok","timestamp":1755620190744,"user_tz":-60,"elapsed":23408,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"71cab6a8-c79a-4b41-ca44-249fc117f925"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["üìä Indoor mixed dataset composition ‚Üí Real: 2000, Synthetic: 2000, Total: 4000\n","‚úÖ Sample label distribution (first 200): Fire=152, No Fire=48\n"]}]},{"cell_type":"markdown","source":["## üß∞ Step 4: Build ResNet-50 (feature extraction), define loss & optimizer\n","\n","We follow the exact **Phase-1 style**: load a pretrained ResNet-50, **freeze the backbone**, replace the final `fc` with a **2-class** head, and train **only** that head.  \n","Use `CrossEntropyLoss` (logits ‚Üí 2 classes) and `Adam` on the head parameters. The checkpoint file name comes from `model_paths[selected_model]`.\n","\n"],"metadata":{"id":"hdFUr1QHXaxM"}},{"cell_type":"code","source":["# --- Step 4: Model (feature extraction), loss, optimizer ---\n","\n","import os\n","import torch\n","import torch.nn as nn\n","from torchvision import models\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# 1) Pretrained ResNet-50 backbone\n","model = models.resnet50(pretrained=True)\n","\n","# 2) Freeze all backbone layers (feature extraction mode)\n","for p in model.parameters():\n","    p.requires_grad = False\n","\n","# 3) Replace classification head with 2-class layer\n","in_features = model.fc.in_features  # typically 2048\n","model.fc = nn.Linear(in_features, 2)\n","\n","# 4) Unfreeze the new head explicitly\n","for p in model.fc.parameters():\n","    p.requires_grad = True\n","\n","# 5) Move to device\n","model = model.to(device)\n","\n","# 6) Loss & optimizer (only head will be trained)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4)\n","\n","# 7) Checkpoint path\n","models_dir = \"/content/drive/MyDrive/fire-detection-dissertation/models\"\n","os.makedirs(models_dir, exist_ok=True)\n","checkpoint_path = os.path.join(models_dir, model_paths[selected_model])\n","\n","# 8) Sanity check\n","trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","total     = sum(p.numel() for p in model.parameters())\n","print(f\"Device: {device} | Trainable params: {trainable} / {total} (only fc)\")\n","print(f\"Checkpoint will be saved to: {checkpoint_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MlK-oNKlSpyV","executionInfo":{"status":"ok","timestamp":1755620223691,"user_tz":-60,"elapsed":477,"user":{"displayName":"Mishara Sapukotanage","userId":"02206396968881771481"}},"outputId":"d7b81b64-9ff7-497c-8b4b-a8a6c37da1b0"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"output_type":"stream","name":"stdout","text":["Device: cuda | Trainable params: 4098 / 23512130 (only fc)\n","Checkpoint will be saved to: /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n"]}]},{"cell_type":"markdown","source":["## üèÉ‚Äç‚ôÇÔ∏è Step 5: Train the model (feature extraction baseline)\n","\n","We use the `train_model()` helper from `utils/train_model.py` to run a standard epoch loop:\n","\n","- Uses GPU if available\n","- Tracks train/valid loss each epoch\n","- Saves the checkpoint **only when val F1 improves** to  \n","  `models/{model_paths[selected_model]}`\n","\n","Training runs for `num_epochs` (default 5) to stay consistent with earlier notebooks.\n"],"metadata":{"id":"viFqM59LZWPB"}},{"cell_type":"code","source":["# --- Step 5: Train using the repo helper ---\n","\n","from utils.train_model import train_model\n","\n","# epochs (keep consistent with earlier phases)\n","num_epochs = 5\n","\n","train_losses, val_losses = train_model(\n","    model=model,\n","    train_loader=train_loader,\n","    val_loader=val_loader,\n","    criterion=criterion,\n","    optimizer=optimizer,\n","    num_epochs=num_epochs,\n","    device=device,\n","    save_path=checkpoint_path,  # e.g., models/resnet_indoor_real_100_phase4.pt\n","    print_every=1,              # print one summary per epoch\n","    print_batch_loss=False      # set True only for debugging\n",")\n","\n","print(\"\\n‚úÖ Training complete.\")\n","print(f\"üì¶ Best model saved to: {checkpoint_path}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sTWzfH7Yew6","outputId":"b88298e3-1081-405b-fdc4-f2217ab23a36"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîç Model device: cuda:0\n","üìå Feature extraction mode: Notebook is responsible for freezing/unfreezing.\n","üìä Trainable parameters: 4098\n","\n","üîÅ Epoch 1/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [1/5] | Train Loss: 0.3785 | Val Loss: 0.4209 | Acc: 0.8700 | Precision: 0.8205 | Recall: 0.9931 | F1: 0.8986 | Time: 195.1s\n","üíæ New best model saved (F1: 0.8986) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n","\n","üîÅ Epoch 2/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [2/5] | Train Loss: 0.2057 | Val Loss: 0.3021 | Acc: 0.9120 | Precision: 0.8994 | Recall: 0.9552 | F1: 0.9264 | Time: 195.0s\n","üíæ New best model saved (F1: 0.9264) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n","\n","üîÅ Epoch 3/5\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [3/5] | Train Loss: 0.1528 | Val Loss: 0.2577 | Acc: 0.9160 | Precision: 0.8974 | Recall: 0.9655 | F1: 0.9302 | Time: 195.2s\n","üíæ New best model saved (F1: 0.9302) ‚Üí /content/drive/MyDrive/fire-detection-dissertation/models/resnet_indoor_50syn_50real_phase4.pt\n","\n","üîÅ Epoch 4/5\n"]},{"output_type":"stream","name":"stderr","text":["                                                              "]},{"output_type":"stream","name":"stdout","text":["‚úÖ Epoch [4/5] | Train Loss: 0.1301 | Val Loss: 0.2266 | Acc: 0.9180 | Precision: 0.9278 | Recall: 0.9310 | F1: 0.9294 | Time: 195.9s\n","\n","üîÅ Epoch 5/5\n"]},{"output_type":"stream","name":"stderr","text":["üöÇ Training:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 112/125 [02:52<00:21,  1.67s/it]"]}]},{"cell_type":"code","source":["# ‚úÖ 1. Navigate to the Git-tracked repo folder\n","%cd /content/fire-detection-dissertation\n","\n","# ‚úÖ 2. Move the notebook from Drive into the repo so Git can track it\n","!mv /content/drive/MyDrive/fire-detection-dissertation/notebooks/07_train_resnet_indoor_models.ipynb /content/fire-detection-dissertation/notebooks/\n","\n","# Optional: confirm it's now inside the repo\n","!ls notebooks/\n","\n","# ‚úÖ 3. Stage the notebook for commit\n","!git add notebooks/07_train_resnet_indoor_models.ipynb\n","\n","# ‚úÖ 4. Commit with a message\n","!git commit -m \"Added Phase 4 indoor training notebook (PLOS ONE real + SYN-FIRE mixed, unnormalised pipeline)\"\n","\n","# ‚úÖ 5. Push to GitHub\n","!git push\n"],"metadata":{"id":"2J-hUrYeaL2g"},"execution_count":null,"outputs":[]}]}